---
title: ''
output: pdf_document
---

\subsection{Conditional Independence and Unobserved Heterogeneity}
\label{Sec:condindependence}


The model construction of section \ref{sec:CRwithCovariates} assumes conditional independence based on the covariates.  In other words, given the information provided by the covariates, the probability of capture on one list is unaffected by another list.  If the assumption does not hold, it may lead to biased parameter estimates.  One reason the conditional independence may be violated is because the capture probabilities upon a list are directly related to the probability of being on another list, i.e., the assumption of list dependency.  This may occur if, for example, one list uses another list as a reference or data is shared between various documentation projects \citep{manrique-vallier_capture-recapture_2020}.  This would lead to heavy positive dependence between these two lists.  While this is a serious issue, we assume the lists used in the analysis are collected independently.

A second reason conditional independence may be violated is that underlying heterogeneity exists within the population that is not fully accounted for by covariates. Recall, the example cited in subsection \ref{sec:earlyapproachlitreview} of individual heterogeneity masquerading as list dependency in the study analyzing extrajudicial killings during the Guatemalan Civil War \citep{ball_making_2000}.  Researchers found that people who were part of Catholic religious communities were more likely to trust Catholic researchers with their stories than with NGO researchers associated with the political left.  Similarly, people located in areas associated with the rebel groups were more likely to do the opposite.  If this trait is unobserved and not taken into account, it will result in biased $\boldsymbol{\beta_j}$ coefficients.  Further, because of the biased coefficients, the probabilities of capture and the estimate for the population size will be biased as well (see section \ref{Sec:simulations}).

\subsubsection{Proposed Extension 2: Modelling the Unobserved Heterogeneity with Latent Classes}

We view the problem of unobserved heterogeneity through the lens of a missing covariates problem.  While there are multiple ways one could implement additional heterogeneity, we choose to add an indicator vector, $\boldsymbol{\omega_i}$, that indicates membership to one of $H_\omega$ latent groups with probability, $\boldsymbol{\phi_\omega}\sim \text{Dirichlet}(\boldsymbol{\alpha_\omega})$.  For simplicity, assume a hyperparameter specification with each value assigned the same value, $\alpha_\omega$.  Larger values of this hyperparameter put more weight on the prior and less on the data. 

This leads to three new types of parameters to sample: $\boldsymbol{\omega_i}$, $\boldsymbol{\phi_\omega}$, and  $\boldsymbol{\beta_\omega}$.  The model is constructed such that each latent group has an additional intercept affecting the probability of capture on each list.  \autoref{eqn:sigmoidfunc} then becomes

\begin{equation}
\label{eqn:sigmoidfunclatentvariable}
\lambda_{ij}=\sigma(\boldsymbol{x_i}^T\boldsymbol{\beta_j} + \boldsymbol{\omega_i}^T\boldsymbol{\beta_\omega}) = \frac{1}{1+e^{-(\boldsymbol{x_i}^T\boldsymbol{\beta_j}+\boldsymbol{\omega_i}^T\boldsymbol{\beta_\omega}))}},
\end{equation}

\subsubsection{Proposed Extension 2: Updating the Estimation}

Since we have three new parameters: $\boldsymbol{\omega_i}$, $\boldsymbol{\phi_\omega}$, and $\boldsymbol{\beta_\omega}$; we might expect to need just three new sampling methods. Unfortunately, complications once again arise from the missing covariates.  If the individual is observed, the latent group membership, $\boldsymbol{\omega_i}$, can be sampled with corresponding discrete probability,

\begin{equation}
\label{eqn:latentvariableomega}
p(\boldsymbol{\omega_i}|\boldsymbol{\phi_\omega},N,\mathcal{Y},\boldsymbol{\beta},\boldsymbol{X}) \propto \phi_\omega\prod_{j=1}^J\lambda_{ij}^{y_{ij}}(1-\lambda_{ij})^{1-y_{ij}}.
\end{equation}

For the individuals that are not observed, we draw the latent class membership during the missing covariate imputation stage. Recall, because of the complications mentioned in subsection \ref{sec:estimationBLRCRMCMC}, the Gibbs sampler requires $N$ and $\mathcal{X}_{mis}$ to be sampled simultaneously.  In order to implement the sampling procedure of the missing covariates, $\mathcal{X}_{mis}$, the latent class membership, $\boldsymbol{\omega_i}$ of each unobserved individual must be drawn initially as well from its subpopulation with probability $\boldsymbol{\phi_\omega}$.

The $\boldsymbol{\phi_\omega}$ are sampled according to,

\begin{equation}
\label{eqn:latentvariablePHIomega}
\boldsymbol{\phi_\omega} \sim \text{Dirichlet}(\alpha_\omega + n_{\omega=1}, \alpha_\omega+n_{\omega=2}, ..., \alpha_\omega+n_{\omega={H_\omega}}),
\end{equation}

where $n_{\omega}$ is the number of individuals belonging to each latent class membership and $\alpha_\omega$ is a hyperparameter which can be thought of as a prior sample size. We set $\alpha_\omega=1$. Lastly, the additional coefficient vector, $\boldsymbol{\beta_\omega}$, can be sampled in the same manner and simultaneously with the other coefficients, $\boldsymbol{\beta_j}$, when conditioned on $\boldsymbol{\phi_\omega}$. 

\subsubsection{Future Work: Implementing Stick-Breaking Priors for Latent Classes}

The current setup uses a finite number of latent classes with a prior specification of a Dirichlet($1/H_\omega$,...,$1/H_\omega$).While it may be reasonable in some cases to know the number of latent classes, it may be advantageous to utilize the stick-breaking prior. Of course, with a sufficiently large $H_\omega$ the current construction will approximate the solution under the stick-breaking prior.  Nevertheless, the current construction uses the concentration parameter, $\alpha_\omega$, as a hyperparameter.  Adding some flexibility by placing a prior on $\alpha_\omega$ could prove beneficial.


\subsubsection{Simulations with Unobserved Heterogeneity}
\label{Sec:simsunobservedheterogeneity}

The final set of simulations is to demonstrate the importance of accounting for both the observed and unobserved heterogeneity. While the cMLCR model has performed well in the prior sections, it has no method of detecting unobservable heterogeneity and hence produces biased estimation. Interestingly, a model like the LCMCR, which is designed to account for unobservable heterogeneity, performs much better, but still struggles as considerable information can be gained by including the covariates. The BLRCR model when extended to include latent intercepts ($H_\omega>1$) can utilize the covariates to detect the observable heterogeneity, but also accounts for the additional unobservable heterogeneity.  As a result, it is the only model that performs well in this subsection.

Data is simulated for three lists (J=3) with one standard normally distributed observed covariate (H=1) and one unobserved covariate indicating membership to a latent group with probability 0.35.  The coefficients used to simulate the data can be found in \autoref{table:heterocoefs}.  Using these coefficients induces positive dependency between lists 1 and 2, but negative dependency between list 3 and the other two lists.  If class membership were known, the list probabilities would still be conditionally independent; however, since these covariates are unobserved, the list probabilities are no longer conditionally independent given the observed data.

\begin{table}[H]
\centering
\begin{tabular}{||c c c c||} 
 \hline
 List ($j$) & $\beta_{0j}$ & $\beta_{1j}$ & $\beta_{\omega j}$   \\ [0.5ex] 
 \hline\hline
 1 & -2.5 &  -1.5  & 3.0 \\ 
 2 & -2.5 & -1.5  &  3.0 \\
 3 & 0.5 & -1.5  &  -3.0 \\
 \hline
\end{tabular}
\caption{Coefficients for Heterogeneity Simulated Data}
\label{table:heterocoefs}
\end{table}


\autoref{table:heterodist} shows the results of 100 simulations on four different population sizes.  It becomes obvious that not accounting for unobserved heterogeneity results in biased estimates for both the BLRCR and cMLCR models.  Recall, the truth with these simulations is there exists two latent classes.  Notice the BLRCR model with the number of hidden classes set at $H_\omega=2$ performs the best in terms of both accuracy and precision.  In a real setting, the number of hidden classes would almost certainly be unknown so we set a sufficiently large value $H_\omega=20$.  While the model doesn't perform quite as well as the aforementioned setting, it dramatically outperforms the methods that do not take unobserved heterogeneity into account.

For situations where observed and unobserved heterogeneity exist, we need a method that accounts for both. It should be noted that the LCMCR model, a methodology that doesn't use covariates, is outperforming the methods that do but assume conditional independence. The LCMCR model is designed to account for unobserved heterogeneity, and since the unobserved heterogeneity plays a substantial role in the capture probability for these simulations, it performs reasonably well. Of course, as we saw in the previous subsections' simulations, the LCMCR does not perform as well as the other methods when most of the heterogeneity can be explained by the covariates.

To further explore the effects of hidden heterogeneity and its detectability, we ran 100 simulations with different coefficients and group percentages.  Using the same coefficients in \autoref{table:heterocoefs}, but adjusting the absolute value of the coefficients, $\beta_{\omega_j}$, we created scenarious that depict different strength levels of heterogeneity.  Trivially, if the coefficient is 0, there is no unobserved heterogeneity in the capture probabilities.  In this situation the algorithm is simply detecting noise that it is mistaking for heterogeneity.  On the other hand, when the absolute value of the $\beta_{\omega j}$ coefficients are set to 5, there is very strong heterogeneity in the capture probabilities for the two groups.  The top plot in \autoref{fig:heterogeneitydiff} shows the mean square error (MSE) of the 100 simulations' posterior median of $N$. A close examination of the plot reveals an overall decrease in the MSE as the heterogeneity strengthens.  This is not surprising as the model is attempting to account for heterogeneity, but if it cannot detect the heterogeneity, it will induce bias.  When the heterogeneity is stronger, the model is more likely to detect this heterogeneity and account for it properly.  


\begin{table}[H]
\centering
\begin{tabular}{||r l r r r r||} 
 \hline
N & Method & N$\%$ &MSE & CI Width & CI $\%$   \\ [0.5ex] 
 \hline\hline

```{r}
#########################################################
####### Heterogeneity Distributions #####################
#########################################################
#Set N and BETA
myN=1000
myBeta="heterogeneity"
mycovariates="onenormwithheterocovs"
myindex <- simdat$N==myN & simdat$BETA==myBeta & simdat$covariates==mycovariates

#test=simdat[myindex,]
#mean(as.numeric(test$cBLRCR))

#Compute Percentage of N
HSPBLRCRNhat = mean(as.numeric(simdat[myindex,]$HSPBLRCR50))/myN
HSPBLRCR2Nhat = mean(as.numeric(simdat[myindex,]$HSPBLRCR2.50))/myN
SPBLRCRNhat = mean(as.numeric(simdat[myindex,]$SPBLRCR50))/myN
normBLRCRNhat = mean(as.numeric(simdat[myindex,]$normBLRCR50))/myN
cMLCRNhat = mean(as.numeric(simdat[myindex,]$cMLCR))/myN
cBLRCRNhat = mean(as.numeric(simdat[myindex,]$cBLRCR))/myN
LCMCRNhat = mean(as.numeric(simdat[myindex,]$LCMCR50))/myN
loglinNhat = mean(as.numeric(simdat[myindex,]$loglin50))/myN
IndependentNhat = mean(as.numeric(simdat[myindex,]$Independent50))/myN

#Check RMSE
HSPBLRCRMSE = RMSE(as.numeric(simdat[myindex,]$HSPBLRCR50),myN)
HSPBLRC2RMSE = RMSE(as.numeric(simdat[myindex,]$HSPBLRCR2.50),myN)
SPBLRCRMSE = RMSE(as.numeric(simdat[myindex,]$SPBLRCR50),myN)
normBLRCRMSE = RMSE(as.numeric(simdat[myindex,]$normBLRCR50),myN)
cMLCRRMSE = RMSE(as.numeric(simdat[myindex,]$cMLCR),myN)
cBLRCRRMSE = RMSE(as.numeric(simdat[myindex,]$cBLRCR),myN)
LCMCRRMSE = RMSE(as.numeric(simdat[myindex,]$LCMCR50),myN)
loglinRMSE = RMSE(as.numeric(simdat[myindex,]$loglin50),myN)
IndependentRMSE = RMSE(as.numeric(simdat[myindex,]$Independent50),myN)

#Average width of interval
cMLCRwidth = mean(as.numeric(simdat[myindex,]$cMLCR97.5)-as.numeric(simdat[myindex,]$cMLCR2.5))/myN
HSPBLRCwidth = mean(as.numeric(simdat[myindex,]$HSPBLRCR97.5)-as.numeric(simdat[myindex,]$HSPBLRCR2.5))/myN
HSPBLRC2width = mean(as.numeric(simdat[myindex,]$HSPBLRCR2.97.5)-as.numeric(simdat[myindex,]$HSPBLRCR2.2.5))/myN
SPBLRCwidth = mean(as.numeric(simdat[myindex,]$SPBLRCR97.5)-as.numeric(simdat[myindex,]$SPBLRCR2.5))/myN
normBLRCwidth = mean(as.numeric(simdat[myindex,]$normBLRCR97.5)-as.numeric(simdat[myindex,]$normBLRCR2.5))/myN
LCMCRwidth = mean(as.numeric(simdat[myindex,]$LCMCR97.5)-as.numeric(simdat[myindex,]$LCMCR2.5))/myN
loglinwidth = mean(as.numeric(simdat[myindex,]$loglin97.5)-as.numeric(simdat[myindex,]$loglin2.5))/myN
Independentwidth = mean(as.numeric(simdat[myindex,]$Independent97.5)-as.numeric(simdat[myindex,]$Independent2.5))/myN

#Check Percentage in Interval
cMLRCCI = mean(as.numeric(simdat[myindex,]$cMLCR2.5)<myN&as.numeric(simdat[myindex,]$cMLCR97.5)>myN)*100
HSPBLRCCI = mean(as.numeric(simdat[myindex,]$HSPBLRCR2.5)<myN&as.numeric(simdat[myindex,]$HSPBLRCR97.5)>myN)*100
HSPBLRC2CI = mean(as.numeric(simdat[myindex,]$HSPBLRCR2.2.5)<myN&as.numeric(simdat[myindex,]$HSPBLRCR2.97.5)>myN)*100
SPBLRCCI = mean(as.numeric(simdat[myindex,]$SPBLRCR2.5)<myN&as.numeric(simdat[myindex,]$SPBLRCR97.5)>myN)*100
normBLRCCI = mean(as.numeric(simdat[myindex,]$normBLRCR2.5)<myN&as.numeric(simdat[myindex,]$normBLRCR97.5)>myN)*100
LCMCRCI = mean(as.numeric(simdat[myindex,]$LCMCR2.5)<myN&as.numeric(simdat[myindex,]$LCMCR97.5)>myN)*100
loglinCI = mean(as.numeric(simdat[myindex,]$loglin2.5)<myN&as.numeric(simdat[myindex,]$loglin97.5)>myN)*100
IndependentCI = mean(as.numeric(simdat[myindex,]$Independent2.5)<myN&as.numeric(simdat[myindex,]$Independent97.5)>myN)*100
```

 1000          & BLRCR($K=1$, $H_\omega=1$)  & `r op(normBLRCRNhat,3)`   & `r op(normBLRCRMSE,1)`   & `r op(normBLRCwidth,3)`   & `r op(normBLRCCI,1)` \\ 
               & BLRCR($K=20$, $H_\omega=1$)    & `r op(SPBLRCRNhat,3)`     & `r op(SPBLRCRMSE,1)`     & `r op(SPBLRCwidth,3)`     & `r op(SPBLRCCI,1)` \\ 
               & BLRCR($K=20$, $H_\omega=2$)    & `r op(HSPBLRCR2Nhat,3)`     & `r op(HSPBLRC2RMSE,1)`     & `r op(HSPBLRC2width,3)`     & `r op(HSPBLRC2CI,1)` \\ 
               & BLRCR($K=20$, $H_\omega=20$)    & `r op(HSPBLRCRNhat,3)`     & `r op(HSPBLRCRMSE,1)`     & `r op(HSPBLRCwidth,3)`     & `r op(HSPBLRCCI,1)` \\ 
               & cMLCR       & `r op(cMLCRNhat,3)`       & `r op(cMLCRRMSE,1)`      & `r op(cMLCRwidth,3)`      & `r op(cMLRCCI,1)` \\
               & Log Linear (BIC)  & `r op(loglinNhat,3)`      & `r op(loglinRMSE,1)`     & `r op(loglinwidth,3)`     & `r op(loglinCI,1)` \\ 
               & LCMCR       & `r op(LCMCRNhat,3)`       & `r op(LCMCRRMSE,1)`      & `r op(LCMCRwidth,3)`      & `r op(LCMCRCI,1)` \\ 
               & Independent & `r op(IndependentNhat,3)` & `r op(IndependentRMSE,1)`& `r op(Independentwidth,3)`& `r op(IndependentCI,1)` \\ 

 \hline
 
```{r}
#########################################################
####### Heterogeneity Distributions #####################
#########################################################
#Set N and BETA
myN=2000
myBeta="heterogeneity"
mycovariates="onenormwithheterocovs"
myindex <- simdat$N==myN & simdat$BETA==myBeta & simdat$covariates==mycovariates

#test=simdat[myindex,]
#mean(as.numeric(test$cBLRCR))

#Compute Percentage of N
HSPBLRCRNhat = mean(as.numeric(simdat[myindex,]$HSPBLRCR50))/myN
HSPBLRCR2Nhat = mean(as.numeric(simdat[myindex,]$HSPBLRCR2.50))/myN
SPBLRCRNhat = mean(as.numeric(simdat[myindex,]$SPBLRCR50))/myN
normBLRCRNhat = mean(as.numeric(simdat[myindex,]$normBLRCR50))/myN
cMLCRNhat = mean(as.numeric(simdat[myindex,]$cMLCR))/myN
cBLRCRNhat = mean(as.numeric(simdat[myindex,]$cBLRCR))/myN
LCMCRNhat = mean(as.numeric(simdat[myindex,]$LCMCR50))/myN
loglinNhat = mean(as.numeric(simdat[myindex,]$loglin50))/myN
IndependentNhat = mean(as.numeric(simdat[myindex,]$Independent50))/myN

#Check RMSE
HSPBLRCRMSE = RMSE(as.numeric(simdat[myindex,]$HSPBLRCR50),myN)
HSPBLRC2RMSE = RMSE(as.numeric(simdat[myindex,]$HSPBLRCR2.50),myN)
SPBLRCRMSE = RMSE(as.numeric(simdat[myindex,]$SPBLRCR50),myN)
normBLRCRMSE = RMSE(as.numeric(simdat[myindex,]$normBLRCR50),myN)
cMLCRRMSE = RMSE(as.numeric(simdat[myindex,]$cMLCR),myN)
cBLRCRRMSE = RMSE(as.numeric(simdat[myindex,]$cBLRCR),myN)
LCMCRRMSE = RMSE(as.numeric(simdat[myindex,]$LCMCR50),myN)
loglinRMSE = RMSE(as.numeric(simdat[myindex,]$loglin50),myN)
IndependentRMSE = RMSE(as.numeric(simdat[myindex,]$Independent50),myN)

#Average width of interval
cMLCRwidth = mean(as.numeric(simdat[myindex,]$cMLCR97.5)-as.numeric(simdat[myindex,]$cMLCR2.5))/myN
HSPBLRCwidth = mean(as.numeric(simdat[myindex,]$HSPBLRCR97.5)-as.numeric(simdat[myindex,]$HSPBLRCR2.5))/myN
HSPBLRC2width = mean(as.numeric(simdat[myindex,]$HSPBLRCR2.97.5)-as.numeric(simdat[myindex,]$HSPBLRCR2.2.5))/myN
SPBLRCwidth = mean(as.numeric(simdat[myindex,]$SPBLRCR97.5)-as.numeric(simdat[myindex,]$SPBLRCR2.5))/myN
normBLRCwidth = mean(as.numeric(simdat[myindex,]$normBLRCR97.5)-as.numeric(simdat[myindex,]$normBLRCR2.5))/myN
LCMCRwidth = mean(as.numeric(simdat[myindex,]$LCMCR97.5)-as.numeric(simdat[myindex,]$LCMCR2.5))/myN
loglinwidth = mean(as.numeric(simdat[myindex,]$loglin97.5)-as.numeric(simdat[myindex,]$loglin2.5))/myN
Independentwidth = mean(as.numeric(simdat[myindex,]$Independent97.5)-as.numeric(simdat[myindex,]$Independent2.5))/myN

#Check Percentage in Interval
cMLRCCI = mean(as.numeric(simdat[myindex,]$cMLCR2.5)<myN&as.numeric(simdat[myindex,]$cMLCR97.5)>myN)*100
HSPBLRCCI = mean(as.numeric(simdat[myindex,]$HSPBLRCR2.5)<myN&as.numeric(simdat[myindex,]$HSPBLRCR97.5)>myN)*100
HSPBLRC2CI = mean(as.numeric(simdat[myindex,]$HSPBLRCR2.2.5)<myN&as.numeric(simdat[myindex,]$HSPBLRCR2.97.5)>myN)*100
SPBLRCCI = mean(as.numeric(simdat[myindex,]$SPBLRCR2.5)<myN&as.numeric(simdat[myindex,]$SPBLRCR97.5)>myN)*100
normBLRCCI = mean(as.numeric(simdat[myindex,]$normBLRCR2.5)<myN&as.numeric(simdat[myindex,]$normBLRCR97.5)>myN)*100
LCMCRCI = mean(as.numeric(simdat[myindex,]$LCMCR2.5)<myN&as.numeric(simdat[myindex,]$LCMCR97.5)>myN)*100
loglinCI = mean(as.numeric(simdat[myindex,]$loglin2.5)<myN&as.numeric(simdat[myindex,]$loglin97.5)>myN)*100
IndependentCI = mean(as.numeric(simdat[myindex,]$Independent2.5)<myN&as.numeric(simdat[myindex,]$Independent97.5)>myN)*100
```

 2000          & BLRCR($K=1$, $H_\omega=1$)  & `r op(normBLRCRNhat,3)`   & `r op(normBLRCRMSE,1)`   & `r op(normBLRCwidth,3)`   & `r op(normBLRCCI,1)` \\ 
               & BLRCR($K=20$, $H_\omega=1$)    & `r op(SPBLRCRNhat,3)`     & `r op(SPBLRCRMSE,1)`     & `r op(SPBLRCwidth,3)`     & `r op(SPBLRCCI,1)` \\
               & BLRCR($K=20$, $H_\omega=2$)    & `r op(HSPBLRCR2Nhat,3)`     & `r op(HSPBLRC2RMSE,1)`     & `r op(HSPBLRC2width,3)`     & `r op(HSPBLRC2CI,1)` \\
               & BLRCR($K=20$, $H_\omega=20$)    & `r op(HSPBLRCRNhat,3)`     & `r op(HSPBLRCRMSE,1)`     & `r op(HSPBLRCwidth,3)`     & `r op(HSPBLRCCI,1)` \\ 
               & cMLCR       & `r op(cMLCRNhat,3)`       & `r op(cMLCRRMSE,1)`      & `r op(cMLCRwidth,3)`      & `r op(cMLRCCI,1)` \\
               & Log Linear (BIC)  & `r op(loglinNhat,3)`      & `r op(loglinRMSE,1)`     & `r op(loglinwidth,3)`     & `r op(loglinCI,1)` \\ 
               & LCMCR       & `r op(LCMCRNhat,3)`       & `r op(LCMCRRMSE,1)`      & `r op(LCMCRwidth,3)`      & `r op(LCMCRCI,1)` \\ 
               & Independent & `r op(IndependentNhat,3)` & `r op(IndependentRMSE,1)`& `r op(Independentwidth,3)`& `r op(IndependentCI,1)` \\ 

 \hline
 
```{r}
#########################################################
####### Heterogeneity Distributions #####################
#########################################################
#Set N and BETA
myN=5000
myBeta="heterogeneity"
mycovariates="onenormwithheterocovs"
myindex <- simdat$N==myN & simdat$BETA==myBeta & simdat$covariates==mycovariates

#test=simdat[myindex,]
#mean(as.numeric(test$cBLRCR))

#Compute Percentage of N
HSPBLRCRNhat = mean(as.numeric(simdat[myindex,]$HSPBLRCR50))/myN
HSPBLRCR2Nhat = mean(as.numeric(simdat[myindex,]$HSPBLRCR2.50))/myN
SPBLRCRNhat = mean(as.numeric(simdat[myindex,]$SPBLRCR50))/myN
normBLRCRNhat = mean(as.numeric(simdat[myindex,]$normBLRCR50))/myN
cMLCRNhat = mean(as.numeric(simdat[myindex,]$cMLCR))/myN
cBLRCRNhat = mean(as.numeric(simdat[myindex,]$cBLRCR))/myN
LCMCRNhat = mean(as.numeric(simdat[myindex,]$LCMCR50))/myN
loglinNhat = mean(as.numeric(simdat[myindex,]$loglin50))/myN
IndependentNhat = mean(as.numeric(simdat[myindex,]$Independent50))/myN

#Check RMSE
HSPBLRCRMSE = RMSE(as.numeric(simdat[myindex,]$HSPBLRCR50),myN)
HSPBLRC2RMSE = RMSE(as.numeric(simdat[myindex,]$HSPBLRCR2.50),myN)
SPBLRCRMSE = RMSE(as.numeric(simdat[myindex,]$SPBLRCR50),myN)
normBLRCRMSE = RMSE(as.numeric(simdat[myindex,]$normBLRCR50),myN)
cMLCRRMSE = RMSE(as.numeric(simdat[myindex,]$cMLCR),myN)
cBLRCRRMSE = RMSE(as.numeric(simdat[myindex,]$cBLRCR),myN)
LCMCRRMSE = RMSE(as.numeric(simdat[myindex,]$LCMCR50),myN)
loglinRMSE = RMSE(as.numeric(simdat[myindex,]$loglin50),myN)
IndependentRMSE = RMSE(as.numeric(simdat[myindex,]$Independent50),myN)

#Average width of interval
cMLCRwidth = mean(as.numeric(simdat[myindex,]$cMLCR97.5)-as.numeric(simdat[myindex,]$cMLCR2.5))/myN
HSPBLRCwidth = mean(as.numeric(simdat[myindex,]$HSPBLRCR97.5)-as.numeric(simdat[myindex,]$HSPBLRCR2.5))/myN
HSPBLRC2width = mean(as.numeric(simdat[myindex,]$HSPBLRCR2.97.5)-as.numeric(simdat[myindex,]$HSPBLRCR2.2.5))/myN
SPBLRCwidth = mean(as.numeric(simdat[myindex,]$SPBLRCR97.5)-as.numeric(simdat[myindex,]$SPBLRCR2.5))/myN
normBLRCwidth = mean(as.numeric(simdat[myindex,]$normBLRCR97.5)-as.numeric(simdat[myindex,]$normBLRCR2.5))/myN
LCMCRwidth = mean(as.numeric(simdat[myindex,]$LCMCR97.5)-as.numeric(simdat[myindex,]$LCMCR2.5))/myN
loglinwidth = mean(as.numeric(simdat[myindex,]$loglin97.5)-as.numeric(simdat[myindex,]$loglin2.5))/myN
Independentwidth = mean(as.numeric(simdat[myindex,]$Independent97.5)-as.numeric(simdat[myindex,]$Independent2.5))/myN

#Check Percentage in Interval
cMLRCCI = mean(as.numeric(simdat[myindex,]$cMLCR2.5)<myN&as.numeric(simdat[myindex,]$cMLCR97.5)>myN)*100
HSPBLRCCI = mean(as.numeric(simdat[myindex,]$HSPBLRCR2.5)<myN&as.numeric(simdat[myindex,]$HSPBLRCR97.5)>myN)*100
HSPBLRC2CI = mean(as.numeric(simdat[myindex,]$HSPBLRCR2.2.5)<myN&as.numeric(simdat[myindex,]$HSPBLRCR2.97.5)>myN)*100
SPBLRCCI = mean(as.numeric(simdat[myindex,]$SPBLRCR2.5)<myN&as.numeric(simdat[myindex,]$SPBLRCR97.5)>myN)*100
normBLRCCI = mean(as.numeric(simdat[myindex,]$normBLRCR2.5)<myN&as.numeric(simdat[myindex,]$normBLRCR97.5)>myN)*100
LCMCRCI = mean(as.numeric(simdat[myindex,]$LCMCR2.5)<myN&as.numeric(simdat[myindex,]$LCMCR97.5)>myN)*100
loglinCI = mean(as.numeric(simdat[myindex,]$loglin2.5)<myN&as.numeric(simdat[myindex,]$loglin97.5)>myN)*100
IndependentCI = mean(as.numeric(simdat[myindex,]$Independent2.5)<myN&as.numeric(simdat[myindex,]$Independent97.5)>myN)*100
```

 5000          & BLRCR($K=1$, $H_\omega=1$)  & `r op(normBLRCRNhat,3)`   & `r op(normBLRCRMSE,1)`   & `r op(normBLRCwidth,3)`   & `r op(normBLRCCI,1)` \\ 
               & BLRCR($K=20$, $H_\omega=1$)    & `r op(SPBLRCRNhat,3)`     & `r op(SPBLRCRMSE,1)`     & `r op(SPBLRCwidth,3)`     & `r op(SPBLRCCI,1)` \\ 
               & BLRCR($K=20$, $H_\omega=2$)    & `r op(HSPBLRCR2Nhat,3)`     & `r op(HSPBLRC2RMSE,1)`     & `r op(HSPBLRC2width,3)`     & `r op(HSPBLRC2CI,1)` \\
               & BLRCR($K=20$, $H_\omega=20$)    & `r op(HSPBLRCRNhat,3)`     & `r op(HSPBLRCRMSE,1)`     & `r op(HSPBLRCwidth,3)`     & `r op(HSPBLRCCI,1)` \\ 
               & cMLCR       & `r op(cMLCRNhat,3)`       & `r op(cMLCRRMSE,1)`      & `r op(cMLCRwidth,3)`      & `r op(cMLRCCI,1)` \\
               & Log Linear (BIC)  & `r op(loglinNhat,3)`      & `r op(loglinRMSE,1)`     & `r op(loglinwidth,3)`     & `r op(loglinCI,1)` \\ 
               & LCMCR       & `r op(LCMCRNhat,3)`       & `r op(LCMCRRMSE,1)`      & `r op(LCMCRwidth,3)`      & `r op(LCMCRCI,1)` \\ 
               & Independent & `r op(IndependentNhat,3)` & `r op(IndependentRMSE,1)`& `r op(Independentwidth,3)`& `r op(IndependentCI,1)` \\ 

 \hline
 
```{r}
#########################################################
####### Heterogeneity Distributions #####################
#########################################################
#Set N and BETA
myN=10000
myBeta="heterogeneity"
mycovariates="onenormwithheterocovs"
myindex <- simdat$N==myN & simdat$BETA==myBeta & simdat$covariates==mycovariates

#test=simdat[myindex,]
#mean(as.numeric(test$cBLRCR))

#Compute Percentage of N
HSPBLRCRNhat = mean(as.numeric(simdat[myindex,]$HSPBLRCR50))/myN
HSPBLRCR2Nhat = mean(as.numeric(simdat[myindex,]$HSPBLRCR2.50))/myN
SPBLRCRNhat = mean(as.numeric(simdat[myindex,]$SPBLRCR50))/myN
normBLRCRNhat = mean(as.numeric(simdat[myindex,]$normBLRCR50))/myN
cMLCRNhat = mean(as.numeric(simdat[myindex,]$cMLCR))/myN
cBLRCRNhat = mean(as.numeric(simdat[myindex,]$cBLRCR))/myN
LCMCRNhat = mean(as.numeric(simdat[myindex,]$LCMCR50))/myN
loglinNhat = mean(as.numeric(simdat[myindex,]$loglin50))/myN
IndependentNhat = mean(as.numeric(simdat[myindex,]$Independent50))/myN

#Check RMSE
HSPBLRCRMSE = RMSE(as.numeric(simdat[myindex,]$HSPBLRCR50),myN)
HSPBLRC2RMSE = RMSE(as.numeric(simdat[myindex,]$HSPBLRCR2.50),myN)
SPBLRCRMSE = RMSE(as.numeric(simdat[myindex,]$SPBLRCR50),myN)
normBLRCRMSE = RMSE(as.numeric(simdat[myindex,]$normBLRCR50),myN)
cMLCRRMSE = RMSE(as.numeric(simdat[myindex,]$cMLCR),myN)
cBLRCRRMSE = RMSE(as.numeric(simdat[myindex,]$cBLRCR),myN)
LCMCRRMSE = RMSE(as.numeric(simdat[myindex,]$LCMCR50),myN)
loglinRMSE = RMSE(as.numeric(simdat[myindex,]$loglin50),myN)
IndependentRMSE = RMSE(as.numeric(simdat[myindex,]$Independent50),myN)

#Average width of interval
cMLCRwidth = mean(as.numeric(simdat[myindex,]$cMLCR97.5)-as.numeric(simdat[myindex,]$cMLCR2.5))/myN
HSPBLRCwidth = mean(as.numeric(simdat[myindex,]$HSPBLRCR97.5)-as.numeric(simdat[myindex,]$HSPBLRCR2.5))/myN
HSPBLRC2width = mean(as.numeric(simdat[myindex,]$HSPBLRCR2.97.5)-as.numeric(simdat[myindex,]$HSPBLRCR2.2.5))/myN
SPBLRCwidth = mean(as.numeric(simdat[myindex,]$SPBLRCR97.5)-as.numeric(simdat[myindex,]$SPBLRCR2.5))/myN
normBLRCwidth = mean(as.numeric(simdat[myindex,]$normBLRCR97.5)-as.numeric(simdat[myindex,]$normBLRCR2.5))/myN
LCMCRwidth = mean(as.numeric(simdat[myindex,]$LCMCR97.5)-as.numeric(simdat[myindex,]$LCMCR2.5))/myN
loglinwidth = mean(as.numeric(simdat[myindex,]$loglin97.5)-as.numeric(simdat[myindex,]$loglin2.5))/myN
Independentwidth = mean(as.numeric(simdat[myindex,]$Independent97.5)-as.numeric(simdat[myindex,]$Independent2.5))/myN

#Check Percentage in Interval
cMLRCCI = mean(as.numeric(simdat[myindex,]$cMLCR2.5)<myN&as.numeric(simdat[myindex,]$cMLCR97.5)>myN)*100
HSPBLRCCI = mean(as.numeric(simdat[myindex,]$HSPBLRCR2.5)<myN&as.numeric(simdat[myindex,]$HSPBLRCR97.5)>myN)*100
HSPBLRC2CI = mean(as.numeric(simdat[myindex,]$HSPBLRCR2.2.5)<myN&as.numeric(simdat[myindex,]$HSPBLRCR2.97.5)>myN)*100
SPBLRCCI = mean(as.numeric(simdat[myindex,]$SPBLRCR2.5)<myN&as.numeric(simdat[myindex,]$SPBLRCR97.5)>myN)*100
normBLRCCI = mean(as.numeric(simdat[myindex,]$normBLRCR2.5)<myN&as.numeric(simdat[myindex,]$normBLRCR97.5)>myN)*100
LCMCRCI = mean(as.numeric(simdat[myindex,]$LCMCR2.5)<myN&as.numeric(simdat[myindex,]$LCMCR97.5)>myN)*100
loglinCI = mean(as.numeric(simdat[myindex,]$loglin2.5)<myN&as.numeric(simdat[myindex,]$loglin97.5)>myN)*100
IndependentCI = mean(as.numeric(simdat[myindex,]$Independent2.5)<myN&as.numeric(simdat[myindex,]$Independent97.5)>myN)*100
```

 10000          & BLRCR($K=1$, $H_\omega=1$)  & `r op(normBLRCRNhat,3)`   & `r op(normBLRCRMSE,1)`   & `r op(normBLRCwidth,3)`   & `r op(normBLRCCI,1)` \\ 
               & BLRCR($K=20$, $H_\omega=1$)    & `r op(SPBLRCRNhat,3)`     & `r op(SPBLRCRMSE,1)`     & `r op(SPBLRCwidth,3)`     & `r op(SPBLRCCI,1)` \\ 
               & BLRCR($K=20$, $H_\omega=2$)    & `r op(HSPBLRCR2Nhat,3)`     & `r op(HSPBLRC2RMSE,1)`     & `r op(HSPBLRC2width,3)`     & `r op(HSPBLRC2CI,1)` \\
               & BLRCR($K=20$, $H_\omega=20$)    & `r op(HSPBLRCRNhat,3)`     & `r op(HSPBLRCRMSE,1)`     & `r op(HSPBLRCwidth,3)`     & `r op(HSPBLRCCI,1)` \\ 
               & cMLCR       & `r op(cMLCRNhat,3)`       & `r op(cMLCRRMSE,1)`      & `r op(cMLCRwidth,3)`      & `r op(cMLRCCI,1)` \\
               & Log Linear (BIC)  & `r op(loglinNhat,3)`      & `r op(loglinRMSE,1)`     & `r op(loglinwidth,3)`     & `r op(loglinCI,1)` \\ 
               & LCMCR       & `r op(LCMCRNhat,3)`       & `r op(LCMCRRMSE,1)`      & `r op(LCMCRwidth,3)`      & `r op(LCMCRCI,1)` \\ 
               & Independent & `r op(IndependentNhat,3)` & `r op(IndependentRMSE,1)`& `r op(Independentwidth,3)`& `r op(IndependentCI,1)` \\ 

 \hline
\end{tabular}
\caption{Results of 100 capture-recapture simulations per algorithm using a standard normal distribution distribution for the known covariate and 0.35 probability of belonging to the latent class.}
\label{table:heterodist}
\end{table}


```{r heterogeneitydiff, fig.align='center',fig.width=9,fig.height=7,fig.margin=TRUE,fig.cap="\\label{fig:strengthheterogeneitydiff}Effect of Strength of Heterogeneity on the Mean Square Error"}
diffleveldataset<-readRDS("simdata/heterogeneitylevelsdata.RDS")

#Edit the data to get MSE for group identification and N
diffleveldataset$sqdiff = (1-diffleveldataset$N50/5000)^2
diffleveldatasetLONG= cbind(rbind(diffleveldataset[,1:5],diffleveldataset[,1:5]),
                            "AME"=c(diffleveldataset[,9],diffleveldataset[,10]),
                            "param"=c(rep("Group Identity",1800),rep("Estimated N",1800)))

#diffleveldataset$intlength = (diffleveldataset$N97.5-diffleveldataset$N2.5)/5000
#aggregate(cbind(sqdiff,intlength)~beta+percgroup,diffleveldataset,mean)

aggdataframe = cbind(
  aggregate(AME~beta+percgroup+param,diffleveldatasetLONG,mean),
  "lower"=aggregate(AME~beta+percgroup+param,diffleveldatasetLONG,function(x){quantile(x,c(0.025),names=FALSE)})[,4],
  "upper"=aggregate(AME~beta+percgroup+param,diffleveldatasetLONG,function(x){quantile(x,c(0.975),names=FALSE)})[,4])

#do this to truncate the upper limits of the N mse (remove if not desired)
#aggdataframe$upper[which(aggdataframe$upper>.0075&aggdataframe$param=="Estimated N")] = .0075

aggdataframe$beta = as.factor(aggdataframe$beta)
aggdataframe$percgroup = as.factor(aggdataframe$percgroup)
pd=position_dodge(0.2)
par(mfrow=c(1,2))
ggplot(aggdataframe, aes(x=beta, y=AME, group=percgroup,color=percgroup)) + 
  facet_grid(param~.,scales="free") +
  geom_point(position=pd, size=3) +
  geom_line(position=pd, size=1) +
  geom_pointrange(aes(ymin=lower, ymax=upper), size=1,position=pd) +
  xlab("Strength of Heterogeneity") +
  ylab("Mean Square Error") +
  scale_colour_hue(name="Percentage in Group 1",    
                   breaks=c("0.1", "0.3", "0.5"),
                   labels=c("0.1", "0.3", "0.5"),
                   l=30) +  
  theme_classic() +
  theme(legend.justification=c(1,0),
        legend.position=c(.95,.75))      
```

The bottom plot in \autoref{fig:heterogeneitydiff} shows the MSE of the average posterior group identifier for the observed data.  In other words, if the first observation actually belongs to the hidden group, $\omega_1$=1, then we find the average number of times the algorithm placed the observation in the first group, $\bar{\omega}_1$.  In the binary case, $H_\omega=2$, the MSE can be computed as

\begin{equation}
MSE = \frac{1}{n}\sum_{i=1}^n (\bar{\omega}_{i} - \omega_i)^2.
\end{equation}

As the heterogeneity strengthens, the detectability of the unobserved groupings increases and the MSE drops considerably.  In the case where the absolute value of $\beta_{\omega j}$ is set to 5, in many of the simulations between 90 and 95$\%$ of the observations are detected correctly in over 90$\%$ of posterior samples.

Unobserved heterogeneity creates a trade off.  On one hand, if the unobserved heterogeneity is weak, there will be relatively little bias in $N$; however, the ability to detect this heterogeneity decreases as well.  On the other hand, When the unobserved heterogeneity is strong, the bias in $N$ will be relatively larger, but the ability to detect and properly account for this heterogeneity increases. 

