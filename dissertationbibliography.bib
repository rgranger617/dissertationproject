
@book{hoff_first_2009,
	title = {A {First} {Course} in {Bayesian} {Statistical} {Methods}},
	publisher = {Springer},
	author = {Hoff, Peter},
	year = {2009},
}

@book{gelman_bayesian_2014,
	edition = {Third},
	title = {Bayesian {Data} {Analysis}},
	publisher = {Chapman \& Hall/CRC},
	author = {Gelman, Andrew and Carlin, John B and Stern, Hal S and Dunson, David B. and Vehtari, Aki and Rubin, Donald B},
	year = {2014},
}

@article{tilling_capture-recapture_1999,
	title = {Capture-{Recapture} {Models} {Including} {Covariate} {Effects}},
	volume = {149},
	issn = {0002-9262, 1476-6256},
	url = {https://academic.oup.com/aje/article-lookup/doi/10.1093/oxfordjournals.aje.a009825},
	doi = {10.1093/oxfordjournals.aje.a009825},
	language = {en},
	number = {4},
	urldate = {2022-04-05},
	journal = {American Journal of Epidemiology},
	author = {Tilling, K. and Sterne, J. A. C.},
	month = feb,
	year = {1999},
	pages = {392--400},
	file = {Tilling and Sterne - 1999 - Capture-Recapture Models Including Covariate Effec.pdf:C\:\\Users\\Rob-IUoffice\\Zotero\\storage\\3NCTNZNV\\Tilling and Sterne - 1999 - Capture-Recapture Models Including Covariate Effec.pdf:application/pdf},
}

@article{huggins_statistical_1989,
	title = {On the {Statistical} {Analysis} of {Capture} {Experiments}},
	volume = {76},
	url = {https://www.jstor.org/stable/2336377},
	abstract = {A procedure is given for estimating the size of a closed population in the presence of heterogeneous capture probabilities using capture-recapture data when it is possible to model the capture probabilities of individuals in the population using covariates. The results include the estimation of the parameters associated with the model of the capture probabilities and the use of these estimated capture probabilities to estimate the population size. Confidence intervals for the population size using both the asymptotic normality of the estimator and a bootstrap procedure for small samples are given.},
	language = {en},
	number = {1},
	journal = {Biometrika},
	author = {Huggins, R M},
	month = mar,
	year = {1989},
	pages = {133--140},
	file = {Huggins - 2022 - On the Statistical Analysis of Capture Experiments.pdf:C\:\\Users\\Rob-IUoffice\\Zotero\\storage\\59GME7V3\\Huggins - 2022 - On the Statistical Analysis of Capture Experiments.pdf:application/pdf},
}

@article{basu_bayesian_2001,
	title = {Bayesian capture-recapture methods for error detection and estimation of population size: {Heterogeneity} and dependence},
	volume = {88},
	issn = {0006-3444, 1464-3510},
	shorttitle = {Bayesian capture-recapture methods for error detection and estimation of population size},
	url = {https://academic.oup.com/biomet/article-lookup/doi/10.1093/biomet/88.1.269},
	doi = {10.1093/biomet/88.1.269},
	abstract = {This paper considers estimation of the unknown size N of a population based on multiple capture-recapture samples. We extend the Bayesian multiple recapture model to accommodate possible heterogeneity and dependence among the samples and possible heterogeneity within the samples. In the dependent model, we show that posterior inference for N is independent of almost all the nuisance parameters. We develop a flexible Bayesian model for heterogeneity within samples and demonstrate how Gibbs sampling can be used to calculate the Bayesian estimator for N and other quantities of interest. The performance of the proposed estimators is evaluated by simulation under both correct and incorrect model specifications, and we illustrate our methods in two examples about software review and estimation of a cottontail rabbit population.},
	language = {en},
	number = {1},
	urldate = {2022-03-27},
	journal = {Biometrika},
	author = {Basu, S.},
	month = feb,
	year = {2001},
	pages = {269--279},
	file = {Basu - 2001 - Bayesian capture-recapture methods for error detec.pdf:C\:\\Users\\Rob-IUoffice\\Zotero\\storage\\GR85XTR9\\Basu - 2001 - Bayesian capture-recapture methods for error detec.pdf:application/pdf},
}

@article{polson_bayesian_2013,
	title = {Bayesian inference for logistic models using {Polya}-{Gamma} latent variables},
	volume = {108},
	doi = {10.1080/01621459.2013.829001},
	abstract = {We propose a new data-augmentation strategy for fully Bayesian inference in models with binomial likelihoods. The approach appeals to a new class of P´olya-Gamma distributions, which are constructed in detail. A variety of examples are presented to show the versatility of the method, including logistic regression, negative binomial regression, nonlinear mixed-eﬀects models, and spatial models for count data. In each case, our data-augmentation strategy leads to simple, eﬀective methods for posterior inference that: (1) circumvent the need for analytic approximations, numerical integration, or Metropolis–Hastings; and (2) outperform other known data-augmentation strategies, both in ease of use and in computational eﬃciency. All methods, including an eﬃcient sampler for the P´olya-Gamma distribution, are implemented in the R package BayesLogit.},
	language = {en},
	number = {504},
	urldate = {2022-03-08},
	journal = {Journal of the American Statistical Association},
	author = {Polson, Nicholas G. and Scott, James G. and Windle, Jesse},
	year = {2013},
	keywords = {Statistics - Machine Learning, Statistics - Methodology, Statistics - Computation},
	pages = {1339--1349},
	file = {Polson et al. - 2013 - Bayesian inference for logistic models using Polya.pdf:C\:\\Users\\Rob-IUoffice\\Zotero\\storage\\4PYA6Q99\\Polson et al. - 2013 - Bayesian inference for logistic models using Polya.pdf:application/pdf},
}

@article{ren_logistic_2011,
	title = {Logistic {Stick}-{Breaking} {Process}},
	volume = {12},
	abstract = {A logistic stick-breaking process (LSBP) is proposed for non-parametric clustering of general spatially- or temporally-dependent data, imposing the belief that proximate data are more likely to be clustered together. The sticks in the LSBP are realized via multiple logistic regression functions, with shrinkage priors employed to favor contiguous and spatially localized segments. The LSBP is also extended for the simultaneous processing of multiple data sets, yielding a hierarchical logistic stick-breaking process (H-LSBP). The model parameters (atoms) within the H-LSBP are shared across the multiple learning tasks. Efﬁcient variational Bayesian inference is derived, and comparisons are made to related techniques in the literature. Experimental analysis is performed for audio waveforms and images, and it is demonstrated that for segmentation applications the LSBP yields generally homogeneous segments with sharp boundaries.},
	language = {en},
	journal = {Journal of Machine Learning Research},
	author = {Ren, Lu and Du, Lan and Carin, Lawrence and Dunson, David},
	year = {2011},
	pages = {203--239},
	file = {Ren et al. - Logistic Stick-Breaking Process.pdf:C\:\\Users\\Rob-IUoffice\\Zotero\\storage\\93DB58G9\\Ren et al. - Logistic Stick-Breaking Process.pdf:application/pdf},
}

@article{dunson_kernel_2008,
	title = {Kernel stick-breaking processes},
	volume = {95},
	issn = {0006-3444, 1464-3510},
	url = {https://academic.oup.com/biomet/article-lookup/doi/10.1093/biomet/asn012},
	doi = {10.1093/biomet/asn012},
	language = {en},
	number = {2},
	urldate = {2022-02-17},
	journal = {Biometrika},
	author = {Dunson, D. B. and Park, J.-H.},
	month = feb,
	year = {2008},
	pages = {307--323},
	file = {Dunson and Park - 2008 - Kernel stick-breaking processes.pdf:C\:\\Users\\Rob-IUoffice\\Zotero\\storage\\9CL2AGYV\\Dunson and Park - 2008 - Kernel stick-breaking processes.pdf:application/pdf},
}

@article{goodman_exploratory_1974,
	title = {Exploratory {Latent} {Structure} {Analysis} {Using} {Both} {Identifiable} and {Unidentifiable} {Models}},
	volume = {61},
	abstract = {This paper considers a wide class of latent structure models. These models can serve as possible explanations of the observed relationships among a set of m manifest polytomous variables. The class of models considered here includes both models in which the parameters are identifiable and also models in which the parameters are not. For each of the models considered here, a relatively simple method is presented for calculating the maximum likelihood estimate of the frequencies in the m-way contingency table expected under the model, and for determining whether the parameters in the estimated model are identifiable. In addition, methods are presented for testing whether the model fits the observed data, and for replacing unidentifiable models that fit by identifiable models that fit. Some illustrative applications to data are also included.},
	language = {en},
	number = {2},
	journal = {Biometrika},
	author = {Goodman, Leo A},
	month = aug,
	year = {1974},
	pages = {215--231},
	file = {Goodman - 2022 - Exploratory Latent Structure Analysis Using Both I.pdf:C\:\\Users\\Rob-IUoffice\\Zotero\\storage\\RXCYAN86\\Goodman - 2022 - Exploratory Latent Structure Analysis Using Both I.pdf:application/pdf},
}

@techreport{sethuraman_constructive_1991,
	address = {Fort Belvoir, VA},
	title = {A {Constructive} {Definition} of {Dirichlet} {Priors}:},
	shorttitle = {A {Constructive} {Definition} of {Dirichlet} {Priors}},
	url = {http://www.dtic.mil/docs/citations/ADA238689},
	abstract = {In this paper we give a simple and new constructive defin measures removing the restriction that the basic space should be 1 complete, self contained proofs of the three basic results for Dirichl 1. The Dirichlet measure is a probability measure on the space of measures. 2. It gives probability one to the subset of discrete probabili 3. The posterior distribution is also a Dirichlet measure.},
	language = {en},
	urldate = {2022-01-25},
	institution = {Defense Technical Information Center},
	author = {Sethuraman, Jayaram},
	month = may,
	year = {1991},
	doi = {10.21236/ADA238689},
	file = {Sethuraman - 1991 - A Constructive Definition of Dirichlet Priors.pdf:C\:\\Users\\Rob-IUoffice\\Zotero\\storage\\23KEN43D\\Sethuraman - 1991 - A Constructive Definition of Dirichlet Priors.pdf:application/pdf},
}

@article{dunson_nonparametric_2009,
	title = {Nonparametric {Bayes} {Modeling} of {Multivariate} {Categorical} {Data}},
	volume = {104},
	issn = {0162-1459, 1537-274X},
	url = {http://www.tandfonline.com/doi/abs/10.1198/jasa.2009.tm08439},
	doi = {10.1198/jasa.2009.tm08439},
	language = {en},
	number = {487},
	urldate = {2022-01-25},
	journal = {Journal of the American Statistical Association},
	author = {Dunson, David B. and Xing, Chuanhua},
	month = sep,
	year = {2009},
	pages = {1042--1051},
	file = {Dunson and Xing - 2009 - Nonparametric Bayes Modeling of Multivariate Categ.pdf:C\:\\Users\\Rob-IUoffice\\Zotero\\storage\\ES9X65FI\\Dunson and Xing - 2009 - Nonparametric Bayes Modeling of Multivariate Categ.pdf:application/pdf},
}

@article{fienberg_integrated_2009,
	title = {Integrated methodology for multiple systems estimation and record linkage using a missing data formulation},
	volume = {93},
	issn = {1863-8171, 1863-818X},
	url = {http://link.springer.com/10.1007/s10182-008-0084-z},
	doi = {10.1007/s10182-008-0084-z},
	abstract = {There are now three essentially separate literatures on the topics of multiple systems estimation, record linkage, and missing data. But in practice the three are intimately intertwined. For example, record linkage involving multiple data sources for human populations is often carried out with the expressed goal of developing a merged database for multiple system estimation (MSE). Similarly, one way to view both the record linkage and MSE problems is as ones involving the estimation of missing data. This presentation highlights the technical nature of these interrelationships and provides a preliminary effort at their integration.},
	language = {en},
	number = {1},
	urldate = {2022-01-24},
	journal = {AStA Advances in Statistical Analysis},
	author = {Fienberg, Stephen E. and Manrique-Vallier, Daniel},
	month = mar,
	year = {2009},
	pages = {49--60},
	file = {Fienberg and Manrique-Vallier - 2009 - Integrated methodology for multiple systems estima.pdf:C\:\\Users\\Rob-IUoffice\\Zotero\\storage\\9FCTGTAZ\\Fienberg and Manrique-Vallier - 2009 - Integrated methodology for multiple systems estima.pdf:application/pdf},
}

@article{manrique-vallier_population_2008,
	title = {Population {Size} {Estimation} {Using} {Individual} {Level} {Mixture} {Models}},
	volume = {50},
	issn = {03233847, 15214036},
	url = {https://onlinelibrary.wiley.com/doi/10.1002/bimj.200810448},
	doi = {10.1002/bimj.200810448},
	abstract = {We revisit the heterogeneous closed population multiple recapture problem, modeling individual-level heterogeneity using the Grade of Membership model (Woodbury et al., 1978). This strategy allows us to postulate the existence of homogeneous latent “ideal” or “pure” classes within the population, and construct a soft clustering of the individuals, where each one is allowed partial or mixed membership in all of these classes. We propose a full hierarchical Bayes specification and a MCMC algorithm to obtain samples from the posterior distribution. We apply the method to simulated data and to three real life examples.},
	language = {en},
	number = {6},
	urldate = {2022-01-24},
	journal = {Biometrical Journal},
	author = {Manrique-Vallier, Daniel and Fienberg, Stephen E.},
	month = dec,
	year = {2008},
	pages = {1051--1063},
	file = {Manrique-Vallier and Fienberg - 2008 - Population Size Estimation Using Individual Level .pdf:C\:\\Users\\Rob-IUoffice\\Zotero\\storage\\VXYG83WN\\Manrique-Vallier and Fienberg - 2008 - Population Size Estimation Using Individual Level .pdf:application/pdf},
}

@article{ball_statistics_2018,
	title = {The {Statistics} of {Genocide}},
	volume = {31},
	issn = {0933-2480, 1867-2280},
	url = {https://www.tandfonline.com/doi/full/10.1080/09332480.2018.1438707},
	doi = {10.1080/09332480.2018.1438707},
	language = {en},
	number = {1},
	urldate = {2022-01-19},
	journal = {CHANCE},
	author = {Ball, Patrick and Price, Megan},
	month = jan,
	year = {2018},
	pages = {38--45},
	file = {Ball and Price - 2018 - The Statistics of Genocide.pdf:C\:\\Users\\Rob-IUoffice\\Zotero\\storage\\TELUEBBI\\Ball and Price - 2018 - The Statistics of Genocide.pdf:application/pdf},
}

@article{ball_killings_2002,
	title = {Killings and {Refugee} {Flow} in {Kosovo}, {March} - {June} 1999: {A} {Report} to the {International} {Criminal} {Tribunal} for the {Former} {Yugoslavia}},
	journal = {American Association for the Advancement of Science (AAAS)},
	author = {Ball, Patrick and Betts, Wendy and Scheuren, Fritz and Dudukovich, Jana and Asher, Jana},
	month = jan,
	year = {2002},
	file = {2002Kosovo-Ball.pdf:C\:\\Users\\Rob-IUoffice\\Zotero\\storage\\WMWRHUGA\\2002Kosovo-Ball.pdf:application/pdf},
}

@book{henderson_ecological_2016,
	edition = {4},
	title = {Ecological {Methods}},
	publisher = {John Wiley and Sons},
	author = {Henderson, Peter Alan and Southwood, T.R.E.},
	month = apr,
	year = {2016},
	file = {ecological_methods_3rd_edition_2000_884.pdf:C\:\\Users\\Rob-IUoffice\\Zotero\\storage\\Z7E9NY7P\\ecological_methods_3rd_edition_2000_884.pdf:application/pdf},
}

@article{goldberg_estimation_1978,
	title = {The {Estimation} of {False} {Negatives} in {Medical} {Screening}},
	volume = {34},
	issn = {0006341X},
	url = {https://www.jstor.org/stable/2529590?origin=crossref},
	doi = {10.2307/2529590},
	abstract = {In a medical screening program for early detection of disease, one or more screening modes are administered to a, apparently healthy population. Knowledge of the true disease status for all screened individuals would allow estimation of the false negative andfalse positive rates/bor each mode of detection and for the program as a whole. This paper develops capture-recapture methods applicable to programs when Jollow-up of individuals negative oil screening is not performed or is incomplete. The methods require at least two independent modes of detection. Data fromn a breast cancer screening program illustrate the procedures. The results of four screening examinations at approximately one-year intervals and the long-term Jollow-up of all screened individuals support the usefulness of these methods in the evaluation oJra screening program.},
	language = {en},
	number = {1},
	urldate = {2022-01-19},
	journal = {Biometrics},
	author = {Goldberg, J. D. and Wittes, J. T.},
	month = mar,
	year = {1978},
	pages = {77--86},
	file = {Goldberg and Wittes - 1978 - The Estimation of False Negatives in Medical Scree.pdf:C\:\\Users\\Rob-IUoffice\\Zotero\\storage\\2N6597IT\\Goldberg and Wittes - 1978 - The Estimation of False Negatives in Medical Scree.pdf:application/pdf},
}

@article{ball_estimate_2003,
	title = {An estimate of the total number of victims killed or disappeared in the armed internal conflict between 1980 and 2000},
	language = {en},
	journal = {AAAS. Report to the Peruvian Truth and Reconciliation Commission (CVR).},
	author = {Ball, Patrick and Asher, Jana and Sulmont, David and Manrique, Daniel},
	year = {2003},
	file = {Ball et al. - An estimate of the total number of victims killed .pdf:C\:\\Users\\Rob-IUoffice\\Zotero\\storage\\DJPTQ4IG\\Ball et al. - An estimate of the total number of victims killed .pdf:application/pdf},
}

@article{baker_simple_1990,
	title = {A {Simple} {EM} {Algorithm} for {Capture}-{Recapture} {Data} with {Categorical} {Covariates}},
	volume = {46},
	issn = {0006341X},
	url = {https://www.jstor.org/stable/2532461?origin=crossref},
	doi = {10.2307/2532461},
	abstract = {A simple EM algorithm is proposed for obtaining maximum likelihood estimates when fitting a loglinear model to data from k capture-recapture samples with categorical covariates. The method is used to analyze data on screening for the early detection of breast cancer.},
	language = {en},
	number = {4},
	urldate = {2022-01-18},
	journal = {Biometrics},
	author = {Baker, S. G.},
	month = dec,
	year = {1990},
	pages = {1193},
	file = {Baker - 1990 - A Simple EM Algorithm for Capture-Recapture Data w.pdf:C\:\\Users\\Rob-IUoffice\\Zotero\\storage\\A9ZTFBV2\\Baker - 1990 - A Simple EM Algorithm for Capture-Recapture Data w.pdf:application/pdf},
}

@article{khabsa_number_2014,
	title = {The {Number} of {Scholarly} {Documents} on the {Public} {Web}},
	volume = {9},
	issn = {1932-6203},
	url = {https://dx.plos.org/10.1371/journal.pone.0093949},
	doi = {10.1371/journal.pone.0093949},
	abstract = {The number of scholarly documents available on the web is estimated using capture/recapture methods by studying the coverage of two major academic search engines: Google Scholar and Microsoft Academic Search. Our estimates show that at least 114 million English-language scholarly documents are accessible on the web, of which Google Scholar has nearly 100 million. Of these, we estimate that at least 27 million (24\%) are freely available since they do not require a subscription or payment of any kind. In addition, at a finer scale, we also estimate the number of scholarly documents on the web for fifteen fields: Agricultural Science, Arts and Humanities, Biology, Chemistry, Computer Science, Economics and Business, Engineering, Environmental Sciences, Geosciences, Material Science, Mathematics, Medicine, Physics, Social Sciences, and Multidisciplinary, as defined by Microsoft Academic Search. In addition, we show that among these fields the percentage of documents defined as freely available varies significantly, i.e., from 12 to 50\%.},
	language = {en},
	number = {5},
	urldate = {2022-01-18},
	journal = {PLoS ONE},
	author = {Khabsa, Madian and Giles, C. Lee},
	editor = {Zhang, Ren},
	month = may,
	year = {2014},
	pages = {e93949},
	file = {Khabsa and Giles - 2014 - The Number of Scholarly Documents on the Public We.pdf:C\:\\Users\\Rob-IUoffice\\Zotero\\storage\\BL4MXQJA\\Khabsa and Giles - 2014 - The Number of Scholarly Documents on the Public We.pdf:application/pdf},
}

@article{lawrence_searching_1998,
	title = {Searching the {World} {Wide} {Web}},
	volume = {280},
	issn = {0036-8075, 1095-9203},
	url = {https://www.science.org/doi/10.1126/science.280.5360.98},
	doi = {10.1126/science.280.5360.98},
	abstract = {The coverage and recency of the major World Wide Web search engines was analyzed, yielding some surprising results. The coverage of any one engine is significantly limited: No single engine indexes more than about one-third of the “indexable Web,” the coverage of the six engines investigated varies by an order of magnitude, and combining the results of the six engines yields about 3.5 times as many documents on average as compared with the results from only one engine. Analysis of the overlap between pairs of engines gives an estimated lower bound on the size of the indexable Web of 320 million pages.},
	language = {en},
	number = {5360},
	urldate = {2022-01-18},
	journal = {Science},
	author = {Lawrence, Steve and Giles, C. Lee},
	month = apr,
	year = {1998},
	pages = {98--100},
	file = {Lawrence and Giles - 1998 - Searching the World Wide Web.pdf:C\:\\Users\\Rob-IUoffice\\Zotero\\storage\\YSQ9B24J\\Lawrence and Giles - 1998 - Searching the World Wide Web.pdf:application/pdf},
}

@article{manrique-vallier_estimating_2019,
	title = {Estimating the {Number} of {Fatal} {Victims} of the {Peruvian} {Internal} {Armed} {Conﬂict}, 1980-2000: an application of modern multi-list {Capture}-{Recapture} techniques},
	abstract = {We estimate the number of fatal victims of the Peruvian internal armed conﬂict between 1980–2000 using stratiﬁed seven-list Capture-Recapture methods based on Dirichlet process mixtures, which we extend to accommodate incomplete stratiﬁcation information. We use matched data from six sources, originally analyzed by the Peruvian Truth and Reconciliation Commission in 2003, together with a new large dataset, originally published in 2006 by the Peruvian government. We deal with missing stratiﬁcation labels by developing a general framework and estimation methods based on MCMC sampling for jointly ﬁtting generic Bayesian Capture-Recapture models and the missing labels. Through a detailed exploration driven by domain-knowledge, modeling and reﬁning, with special precautions to avoid cherry-picking of results, we arrive to a conservative posterior estimate of 58,234 (CI95\% = [56,741, 61,289]), and a more liberal estimate of 65,958 (CI95\% = [61,462, 75,387]) fatal victims. We also determine that the Shining Path guerrillas killed more people than the Peruvian armed forces. We additionally explore and discuss estimates based on log-linear modeling and multiple-imputation. We ﬁnish by discussing several lessons learned about the use of Capture-Recapture methods for estimating casualties in conﬂicts.},
	language = {en},
	author = {Manrique-Vallier, Daniel and Ball, Patrick and Sulmont, David},
	year = {2019},
	file = {Manrique-Vallier et al. - Estimating the Number of Fatal Victims of the Peru.pdf:C\:\\Users\\Rob-IUoffice\\Zotero\\storage\\VRPRF3HB\\Manrique-Vallier et al. - Estimating the Number of Fatal Victims of the Peru.pdf:application/pdf},
}

@article{alho_logistic_1990,
	title = {Logistic {Regression} in {Capture}-{Recapture} {Models}},
	volume = {46},
	issn = {0006341X},
	url = {https://www.jstor.org/stable/2532083?origin=crossref},
	doi = {10.2307/2532083},
	abstract = {The effect of population heterogeneity in capture-recapture, or dual registration, models is discussed. An estimator of the unknown population size based on a logistic regression model is introduced. The model allows different capture probabilities across individuals and across capture times. The probabilities are estimated from the observed data using conditional maximum likelihood. The resulting population estimator is shown to be consistent and asymptotically normal. A variance estimator under population heterogeneity is derived. The finite-sample properties of the estimators are studied via simulation. An application to Finnish occupational disease registration data is presented.},
	language = {en},
	number = {3},
	urldate = {2022-01-18},
	journal = {Biometrics},
	author = {Alho, Juha M.},
	month = sep,
	year = {1990},
	pages = {623},
	file = {Alho - 1990 - Logistic Regression in Capture-Recapture Models.pdf:C\:\\Users\\Rob-IUoffice\\Zotero\\storage\\YHIHM3NI\\Alho - 1990 - Logistic Regression in Capture-Recapture Models.pdf:application/pdf},
}

@article{darroch_three-sample_1993,
	title = {A {Three}-{Sample} {Multiple}-{Recapture} {Approach} to {Census} {Population} {Estimation} {With} {Heterogeneous} ·catchability},
	language = {en},
	journal = {Journal of the American Statistical Association},
	author = {Darroch, John N and Fienberg, Stephen E and Glonek, Gary F V and Junker, Brian W},
	year = {1993},
	pages = {13},
	file = {Darroch et al. - 1993 - A Three-Sample Multiple-Recapture Approach to Cens.pdf:C\:\\Users\\Rob-IUoffice\\Zotero\\storage\\LRB75FQK\\Darroch et al. - 1993 - A Three-Sample Multiple-Recapture Approach to Cens.pdf:application/pdf},
}

@book{rasch_probabalistic_1960,
	address = {Chicago},
	title = {Probabalistic {Models} for {Some} {Intelligence} and {Attainment} {Tests}},
	publisher = {University of Chicago Press},
	author = {Rasch, Georg},
	year = {1960},
}

@article{fienberg_classical_1999,
	series = {Series {A}},
	title = {Classical {Multilevel} and {Bayesian} {Approaches} to {Population} {Size} {Estimation} {Using} {Multiple} {Lists}},
	volume = {162},
	number = {3},
	journal = {Journal of Royal Statistical Society},
	author = {Fienberg, Stephen E and Johnson, Matthew S and Junker, Brian W},
	year = {1999},
	pages = {383--405},
	file = {1999-Fienberg_etal_bayesian_JRSSA.pdf:C\:\\Users\\Rob-IUoffice\\Zotero\\storage\\D4F8YMJL\\1999-Fienberg_etal_bayesian_JRSSA.pdf:application/pdf},
}

@book{ball_making_2000,
	address = {Washington, D.C.},
	title = {Making the case: investigating large scale human rights violations using information systems and data analysis},
	isbn = {978-0-87168-652-7},
	shorttitle = {Making the case},
	language = {en},
	publisher = {American Association for the Advancement of Science},
	author = {Ball, Patrick and Spirer, Herbert F and Spirer, Louise},
	year = {2000},
	file = {Ball et al. - 2000 - Making the case investigating large scale human r.pdf:C\:\\Users\\Rob-IUoffice\\Zotero\\storage\\QBGFKJSV\\Ball et al. - 2000 - Making the case investigating large scale human r.pdf:application/pdf},
}

@article{manrique-vallier_capture-recapture_2020,
	title = {Capture-{Recapture} for {Casualty} {Estimation} and {Beyond}: {Recent} {Advances} and {Research} {Directions}},
	abstract = {The most basic quantitative question about the consequences of armed conﬂicts is perhaps how many people were killed. During and after conﬂicts, it is common to attempt to create tallies of victims. However, destroyed infrastructure and institutions, danger to ﬁeld workers, and a reasonable suspicion of data collection by victim communities limit the result of these eﬀorts to incomplete and non-representative lists. Capture-Recapture (CR) estimation, also known as Multiple Systems Estimation (MSE) in the context of human populations, is a family of methods for estimating the size of closed populations based on matched incomplete samples. CR methods vary in details and complexity, but they all ultimately rely on analyzing the patterns of inclusion of individuals across samples to estimate the probability of not being observed and then the number of unobserved individuals. In this discussion, we describe the versions MSE with which analysts have estimated the total number casualties in armed conﬂicts. We explore the advances of the last ﬁfteen years, and we describe outstanding statistical challenges.},
	language = {en},
	author = {Manrique-Vallier, Daniel and Ball, Patrick and Sadinle, Mauricio},
	year = {2020},
	file = {2020Manrique-Ball-Sadinle-CaptureReCaptureforCasualtyEstimationandBeyond.pdf:C\:\\Users\\Rob-IUoffice\\Zotero\\storage\\UM7L4DMZ\\2020Manrique-Ball-Sadinle-CaptureReCaptureforCasualtyEstimationandBeyond.pdf:application/pdf;Manrique-Vallier et al. - Capture-Recapture for Casualty Estimation and Beyo.pdf:C\:\\Users\\Rob-IUoffice\\Zotero\\storage\\BZXM9G8T\\Manrique-Vallier et al. - Capture-Recapture for Casualty Estimation and Beyo.pdf:application/pdf},
}

@article{sanathanan_models_1972,
	title = {Models and {Estimation} {Methods} in {Visual} {Scanning} {Experiments}},
	volume = {14},
	doi = {10.2307/1267131},
	abstract = {This paper deals with a problem that often arises in visual scanning experiments in particle physics, viz. that of estimating the number of undetected particles from the scanning record. This problem is formulated here as one in estimating the size of a multinomial population from an incomplete observation of the cell totals under constraints on the cell probabilities. These constraints differ according to the assumptions made about the scanners and the particles, thus giving rise to different probability models. Several models are considered here-existing ones as well as a new generalized model (Sections 2, 4, 5) Estimation procedures corresponding to these models are discussed (Sections 6-10). A discussion of the applicability of the techniques presented here to other areas is also included (Section 1). A table of the notation used in this paper is provided in Section 3.},
	language = {en},
	number = {4},
	journal = {Technometrics},
	author = {Sanathanan, Lalitha},
	month = nov,
	year = {1972},
	pages = {813--829},
	file = {2021 - Models and Estimation Methods in Visual Scanning E.pdf:C\:\\Users\\Rob-IUoffice\\Zotero\\storage\\43K77N2E\\2021 - Models and Estimation Methods in Visual Scanning E.pdf:application/pdf},
}

@article{fienberg_multiple_1972,
	title = {The {Multiple} {Recapture} {Census} for {Closed} {Populations} and {Incomplete} 2k {Contingency} {Tables}},
	volume = {59},
	doi = {10.2307/2334810},
	abstract = {The multiple recapture census for closed populations is reconsidered, assuming an underlying multinomial sampling model. The resulting data can be put in the form of an incomplete 2k contingency table, with one missing cell, that displays the full multiple recapture history of all individuals in the population. Log linear models are fitted to this incomplete contingency table, and the simplest plausible model that fits the observed cells is projected to cover the missing cell, thus yielding an estimate of the total population size. Asymptotic variances for the estimate of the population size are considered, and the techniques are illustrated on a population of children possessing a common congenital anomaly.},
	language = {en},
	number = {3},
	journal = {Biometrika},
	author = {Fienberg, Stephen E},
	month = dec,
	year = {1972},
	pages = {591--603},
	file = {Fienberg - 2021 - The multiple recapture census for closed populatio.pdf:C\:\\Users\\Rob-IUoffice\\Zotero\\storage\\K2GZJPZ2\\Fienberg - 2021 - The multiple recapture census for closed populatio.pdf:application/pdf},
}

@article{guberek_count_2010,
	title = {To {Count} the {Uncounted}: {An} {Estimation} of {Lethal} {Violence} in {Casanare}},
	language = {en},
	urldate = {2022-01-17},
	journal = {Benetech Human Rights Program},
	author = {Guberek, Tamy and Guzman, Daniel and Price, Megan and Lum, Kristian and Ball, Patrick},
	month = feb,
	year = {2010},
	pages = {1--31},
	file = {Guberek et al. - To Count the Uncounted An Estimation of Lethal Vi.pdf:C\:\\Users\\Rob-IUoffice\\Zotero\\storage\\2PVIYWB6\\Guberek et al. - To Count the Uncounted An Estimation of Lethal Vi.pdf:application/pdf},
}

@article{lincoln_calculating_1930,
	title = {Calculating {Waterfowl} {Abundance} on the {Basis} of {Banding} {Returns}},
	volume = {Circular 118},
	journal = {United States Department of Agriculture},
	author = {Lincoln, Frederick C.},
	month = may,
	year = {1930},
}

@article{petersen_yearly_1895,
	title = {The yearly immigration of young plaice into the limfjord from the german sea.},
	journal = {The Danish Biological Station},
	author = {Petersen, C.G. Johannes},
	year = {1895},
}

@article{schaefer_estimation_1951,
	title = {Estimation of {Size} of {Animal} {Populations} by {Marking} {Experiments}},
	volume = {52},
	number = {69},
	journal = {Fishery Bulletin},
	author = {Schaefer, Milner B},
	year = {1951},
	pages = {191--203},
	file = {Fishery_Bulletin_of_the_Fish_and_Wildlif.pdf:C\:\\Users\\Rob\\OneDrive\\Documents\\Indiana University Statistics Graduate Program\\Dissertation\\literature\\Fishery_Bulletin_of_the_Fish_and_Wildlif.pdf:application/pdf},
}

@article{manriquevallier_bayesian_2016,
	title = {Bayesian {Population} {Size} {Estimation} using {Dirichlet} {Process} {Mixtures}},
	volume = {72},
	issn = {0006-341X, 1541-0420},
	url = {https://onlinelibrary.wiley.com/doi/10.1111/biom.12502},
	doi = {10.1111/biom.12502},
	abstract = {We introduce a new Bayesian nonparametric method for estimating the size of a closed population from multiplerecapture data. Our method, based on Dirichlet process mixtures, can accommodate complex patterns of heterogeneity of capture, and can transparently modulate its complexity without a separate model selection step. Additionally, it can handle the massively sparse contingency tables generated by large number of recaptures with moderate sample sizes. We develop an eﬃcient and scalable MCMC algorithm for estimation. We apply our method to simulated data, and to two examples from the literature of estimation of casualties in armed conﬂicts.},
	language = {en},
	number = {4},
	urldate = {2022-01-13},
	journal = {Biometrics},
	author = {Manrique‐Vallier, Daniel},
	year = {2016},
	pages = {1246--1254},
	file = {Manrique‐Vallier - 2016 - Bayesian population size estimation using Dirichle.pdf:C\:\\Users\\Rob-IUoffice\\Zotero\\storage\\HR7V2UC4\\Manrique‐Vallier - 2016 - Bayesian population size estimation using Dirichle.pdf:application/pdf},
}

@article{yee_vgam_2015,
	title = {The \textbf{{VGAM}} {Package} for {Capture}-{Recapture} {Data} {Using} the {Conditional} {Likelihood}},
	volume = {65},
	issn = {1548-7660},
	url = {http://www.jstatsoft.org/v65/i05/},
	doi = {10.18637/jss.v065.i05},
	abstract = {It is well known that using individual covariate information (such as body weight or gender) to model heterogeneity in capture-recapture (CR) experiments can greatly enhance inferences on the size of a closed population. Since individual covariates are only observable for captured individuals, complex conditional likelihood methods are usually required and these do not constitute a standard generalized linear model (GLM) family. Modern statistical techniques such as generalized additive models (GAMs), which allow a relaxing of the linearity assumptions on the covariates, are readily available for many standard GLM families. Fortunately, a natural statistical framework for maximizing conditional likelihoods is available in the Vector GLM and Vector GAM classes of models. We present several new R functions (implemented within the VGAM package) speciﬁcally developed to allow the incorporation of individual covariates in the analysis of closed population CR data using a GLM/GAM-like approach and the conditional likelihood. As a result, a wide variety of practical tools are now readily available in the VGAM object oriented framework. We discuss and demonstrate their advantages, features and ﬂexibility using the new VGAM CR functions on several examples.},
	language = {en},
	number = {5},
	urldate = {2022-10-11},
	journal = {Journal of Statistical Software},
	author = {Yee, Thomas W. and Stoklosa, Jakub and Huggins, Richard M.},
	year = {2015},
	file = {Yee et al. - 2015 - The VGAM Package for Capture-Recapture Data.pdf:C\:\\Users\\Rob-IUoffice\\Zotero\\storage\\VYHF28YM\\Yee et al. - 2015 - The VGAM Package for Capture-Recapture Data.pdf:application/pdf},
}

@article{horvitz_generalization_1952,
	title = {A {Generalization} of {Sampling} {Without} {Replacement} {From} a {Finite} {Universe}},
	volume = {47},
	language = {en},
	number = {260},
	journal = {Journal of the American Statistical Association},
	author = {Horvitz, D G and Thompson, D J},
	year = {1952},
	pages = {663--685},
	file = {HORVITZt and Thompson - 2022 - A Generalization of Sampling Without Replacement F.pdf:C\:\\Users\\Rob-IUoffice\\Zotero\\storage\\HLS5WN3W\\HORVITZt and Thompson - 2022 - A Generalization of Sampling Without Replacement F.pdf:application/pdf},
}

@article{darroch_multiple-recapture_1958,
	title = {The {Multiple}-{Recapture} {Census}: {I}. {Estimation} of a {Closed} {Population}},
	volume = {45},
	language = {en},
	number = {3/4},
	journal = {Biometrika},
	author = {Darroch, J N},
	month = dec,
	year = {1958},
	pages = {343--359},
	file = {Darroch - 2022 - The Multiple-Recapture Census I. Estimation of a .pdf:C\:\\Users\\Rob-IUoffice\\Zotero\\storage\\ARKTFX3R\\Darroch - 2022 - The Multiple-Recapture Census I. Estimation of a .pdf:application/pdf},
}

@article{schnabel_estimation_1938,
	title = {The {Estimation} of {Total} {Fish} {Population} of a {Lake}},
	volume = {45},
	issn = {00029890},
	url = {http://www.jstor.org/stable/2304025?origin=crossref},
	doi = {10.2307/2304025},
	language = {en},
	number = {6},
	urldate = {2022-11-08},
	journal = {The American Mathematical Monthly},
	author = {Schnabel, Zoe Emily},
	month = jun,
	year = {1938},
	pages = {348},
	file = {Schnabel - 1938 - The Estimation of Total Fish Population of a Lake.pdf:C\:\\Users\\Rob-IUoffice\\Zotero\\storage\\EMH7NLYA\\Schnabel - 1938 - The Estimation of Total Fish Population of a Lake.pdf:application/pdf},
}

@article{geiger_zahl_1924,
	title = {Die {Zahl} der von {Radium} ausgesandten a-{Teilchen}},
	volume = {21},
	journal = {Zeitschrift für Physik},
	author = {Geiger, H. and Werner, A},
	year = {1924},
	pages = {187--201},
}

@article{pledger_unified_2000,
	title = {Unified {Maximum} {Likelihood} {Estimates} for {Closed} {Capture}-{Recapture} {Models} {Using} {Mixtures}},
	volume = {56},
	issn = {0006341X},
	url = {https://onlinelibrary.wiley.com/doi/10.1111/j.0006-341X.2000.00434.x},
	doi = {10.1111/j.0006-341X.2000.00434.x},
	abstract = {Agresti (1994, Biometrics 50, 494-500) and Norris and Pollock (1996a, Biometrics 52, 639649) suggested using methods of finite mixtures to partition the animals in a closed capture-recapture experiment into two or more groups with relatively homogeneous capture probabilities. This enabled them to fit the models Mh, Mbh (Norris and Pollock), and Mth (Agresti) of Otis et al. (1978, Wildlife Monographs 62, 1-135). In this article, finite mixture partitions of animals and/or samples are used to give a unified linear-logistic framework for fitting all eight models of Otis et al. by maximum likelihood. Likelihood ratio tests are available for model comparisons. For many data sets, a simple dichotomy of animals is enough to substantially correct for heterogeneity-induced bias in the estimation of population size, although there is the option of fitting more than two groups if the data warrant it.},
	language = {en},
	number = {2},
	urldate = {2022-11-17},
	journal = {Biometrics},
	author = {Pledger, Shirley},
	month = jun,
	year = {2000},
	pages = {434--442},
	file = {Pledger - 2000 - Unified Maximum Likelihood Estimates for Closed Ca.pdf:C\:\\Users\\Rob-IUoffice\\Zotero\\storage\\6NPDR8IC\\Pledger - 2000 - Unified Maximum Likelihood Estimates for Closed Ca.pdf:application/pdf},
}

@article{alpizar-jara_combination_1996,
	title = {A combination line transect and capture-recapture sampling model for multiple observers in aerial surveys},
	volume = {3},
	issn = {1352-8505, 1573-3009},
	url = {http://link.springer.com/10.1007/BF00539369},
	doi = {10.1007/BF00539369},
	abstract = {We present a robust sampling methodology to estimate population sizeusing line transect and capture-recapture procedures for aerial surveys. Aerial surveys usually underestimate population density due to animals being missed. A combination of capture-recapture and line transect sampling methods with multiple observers allows violation of the assumption that all animals on the centreline are sighted from the air. We illustrate our method with an example of inanimate objects which shows evidence of failure of the assumption that all objects on the centreline have probability 1 of being detected. A simulation study is implemented to evaluate the performance of three variations of the Lincoln-Petersen estimator: the overall estimator, the stratified estimator, and the general stratified estimator based on the combined likelihood proposed in this paper. The stratified Lincoln-Petersen estimator based on the combined likelihood is found to be generally superior to the other estimators.},
	language = {en},
	number = {4},
	urldate = {2022-11-15},
	journal = {Environmental and Ecological Statistics},
	author = {Alpizar-Jara, Russell and Pollock, Kenneth H.},
	month = dec,
	year = {1996},
	pages = {311--327},
	file = {Alpizar-Jara and Pollock - 1996 - A combination line transect and capture-recapture .pdf:C\:\\Users\\Rob-IUoffice\\Zotero\\storage\\PTSY5284\\Alpizar-Jara and Pollock - 1996 - A combination line transect and capture-recapture .pdf:application/pdf},
}

@article{borchers_mark-recapture_1998,
	title = {Mark-{Recapture} {Models} for {Line} {Transect} {Surveys}},
	volume = {54},
	issn = {0006341X},
	url = {https://www.jstor.org/stable/2533651?origin=crossref},
	doi = {10.2307/2533651},
	abstract = {One of the key assumptions of conventional line transect (LT) theory is that all animals in the observer's path are detected. When this assumption fails, simultaneous survey by two independent observers can be used to estimate detection probabilities and abundance. Models are developed for such surveys for both grouped and ungrouped perpendicular distance data. The models unify and generalize existing line transect and mark-recapture models. They provide a general framework for the estimation of abundance from LT surveys in which detection of animals on the trackline is not certain and/or the probability of detection depends on perpendicular distance and additional covariates. Existing LT models in the literature are obtained as special cases of the general models. We use data from a shipboard line transect survey of Antarctic minke whales to illustrate use of the models.},
	language = {en},
	number = {4},
	urldate = {2022-11-15},
	journal = {Biometrics},
	author = {Borchers, David L. and Zucchini, Walter and Fewster, Rachel M.},
	month = dec,
	year = {1998},
	pages = {1207--1220},
	file = {Borchers et al. - 1998 - Mark-Recapture Models for Line Transect Surveys.pdf:C\:\\Users\\Rob-IUoffice\\Zotero\\storage\\VVIGN68P\\Borchers et al. - 1998 - Mark-Recapture Models for Line Transect Surveys.pdf:application/pdf},
}

@article{pollock_use_1984,
	title = {The {Use} of {Auxiliary} {Variables} in {Capture}-{Recapture} and {Removal} {Experiments}},
	volume = {40},
	issn = {0006341X},
	url = {https://www.jstor.org/stable/2531386?origin=crossref},
	doi = {10.2307/2531386},
	abstract = {The dependence of animal capture probabilities on auxiliary variables is an important practical problem which has not been considered in the development of estimation procedures for capturerecapture and removal experiments. In this paper the linear logistic binary regression model is used to relate the probability of capture to continuous auxiliary variables. The auxiliary variables could be environmental quantities such as air or water temperature, or characteristics of individual animals, such as body length or weight. Maximum likelihood estimators of the population parameters are considered for a variety of models which all assume a closed population. Testing between models is also considered. The models can also be used when one auxiliary variable is a measure of the effort expended in obtaining the sample.},
	language = {en},
	number = {2},
	urldate = {2022-11-13},
	journal = {Biometrics},
	author = {Pollock, Kenneth H. and Hines, James E. and Nichols, James D.},
	month = jun,
	year = {1984},
	pages = {329--340},
	file = {Pollock et al. - 1984 - The Use of Auxiliary Variables in Capture-Recaptur.pdf:C\:\\Users\\Rob-IUoffice\\Zotero\\storage\\HKDG5E7N\\Pollock et al. - 1984 - The Use of Auxiliary Variables in Capture-Recaptur.pdf:application/pdf},
}

@book{national_research_council_2000_2004,
	address = {Washington, D.C.},
	title = {The 2000 {Census}: {Counting} {Under} {Adversity}},
	url = {https://doi.org/10.17226/10907},
	publisher = {National Academies Press},
	author = {{National Research Council}},
	year = {2004},
}

@article{howard_study_1948,
	title = {A study of {Tagging} {Method} in the {Enumeration} of {Sockeye} {Salmon} {Populations}},
	volume = {Bulletin II},
	journal = {International Pacific Salmon Fisheries Commission},
	author = {Howard, Gerald Vincent},
	year = {1948},
	file = {Gerald Vincent Howard - 1948 - A study of Tagging Method in the Enumeration of So.pdf:C\:\\Users\\Rob-IUoffice\\Zotero\\storage\\BR2RUP36\\Gerald Vincent Howard - 1948 - A study of Tagging Method in the Enumeration of So.pdf:application/pdf},
}

@article{sekar_method_1949,
	title = {On a {Method} of {Estimating} {Birth} and {Death} {Rates} and the {Extent} of {Registration}},
	volume = {44},
	language = {en},
	number = {245},
	journal = {Journal of the American Statistical Association},
	author = {Sekar, C Chandra and Deming, Edwards},
	month = mar,
	year = {1949},
	pages = {101--115},
	file = {Se - 2022 - On a Method of Estimating Birth and Death Rates an.pdf:C\:\\Users\\Rob-IUoffice\\Zotero\\storage\\RIAQW5H6\\Se - 2022 - On a Method of Estimating Birth and Death Rates an.pdf:application/pdf},
}

@misc{das_doubly_2021,
	title = {Doubly robust capture-recapture methods for estimating population size},
	url = {http://arxiv.org/abs/2104.14091},
	abstract = {Estimation of population size using incomplete lists (also called the capture-recapture problem) has a long history across many biological and social sciences. For example, human rights groups often construct partial and overlapping lists of victims of armed conﬂicts, with the hope of using this information to estimate the total number of victims. Earlier statistical methods for this setup either use potentially restrictive parametric assumptions, or else rely on typically suboptimal plug-in-type nonparametric estimators; however, both approaches can lead to substantial bias, the former via model misspeciﬁcation and the latter via smoothing. Under an identifying assumption that two lists are conditionally independent given measured covariate information, we make several contributions. First we derive the nonparametric eﬃciency bound for estimating the capture probability, which indicates the best possible performance of any estimator, and sheds light on the statistical limits of capture-recapture methods. Then we present a new estimator, and study its ﬁnite-sample properties, showing that it has a double robustness property new to capture-recapture, and that it is near-optimal in a non-asymptotic sense, under relatively mild nonparametric conditions. Next, we give a method for constructing conﬁdence intervals for total population size from generic capture probability estimators, and prove non-asymptotic nearvalidity. Finally, we study our methods in simulations, and apply them to estimate the number of killings and disappearances attributable to diﬀerent groups in Peru during its internal armed conﬂict between 1980 and 2000.},
	language = {en},
	urldate = {2022-11-09},
	publisher = {arXiv},
	author = {Das, Manjari and Kennedy, Edward H. and Jewell, Nicholas P.},
	month = jul,
	year = {2021},
	note = {Number: arXiv:2104.14091
arXiv:2104.14091 [math, stat]},
	keywords = {Mathematics - Statistics Theory, Statistics - Methodology},
	annote = {Comment: 20 pages, 7 figures},
	file = {Das et al. - 2021 - Doubly robust capture-recapture methods for estima.pdf:C\:\\Users\\Rob-IUoffice\\Zotero\\storage\\YH6P5SWP\\Das et al. - 2021 - Doubly robust capture-recapture methods for estima.pdf:application/pdf},
}

@article{zwane_population_2005,
	title = {Population estimation using the multiple system estimator in the presence of continuous covariates},
	volume = {5},
	issn = {1471-082X, 1477-0342},
	url = {http://journals.sagepub.com/doi/10.1191/1471082X05st086oa},
	doi = {10.1191/1471082X05st086oa},
	abstract = {In the presence of continuous covariates, standard capture–recapture methods assume either that the registrations operate independently at the individual level or that the covariates can be stratiﬁed and log-linear models ﬁtted, permitting the modelling of dependence between data sources. This article introduces an approach where direct dependence between registrations is modelled leaving the continuous covariates in their measurement scale. Simulations show that not accounting for possible dependence between registrations results in biased estimation of both the population size and standard error. The proposed method is applied to Dutch neural tube defect registration data.},
	language = {en},
	number = {1},
	urldate = {2022-11-09},
	journal = {Statistical Modelling},
	author = {Zwane, Eugene and van der Heijden, Peter},
	month = apr,
	year = {2005},
	pages = {39--52},
	file = {Zwane and van der Heijden - 2005 - Population estimation using the multiple system es.pdf:C\:\\Users\\Rob-IUoffice\\Zotero\\storage\\8LTNDVNY\\Zwane and van der Heijden - 2005 - Population estimation using the multiple system es.pdf:application/pdf},
}

@article{pollock_use_2002,
	title = {The use of auxiliary variables in capture-recapture modelling: {An} overview},
	volume = {29},
	issn = {0266-4763, 1360-0532},
	shorttitle = {The use of auxiliary variables in capture-recapture modelling},
	url = {https://www.tandfonline.com/doi/full/10.1080/02664760120108430},
	doi = {10.1080/02664760120108430},
	abstract = {I review the use of auxiliary variables in capture- recapture models for estimation of demog raphic parameters (e.g. capture probability, population size, sur vival probability, and recruitment, emig ration and immigration numbers). I focus on what has been done in current research and what still needs to be done. Typically in the literature, covariate modelling has made capture and sur vival probabilities functions of covariates, but there are good reasons also to make other parameters functions of covariates as well. The types of covariates considered include environmental covariates that may vary by occasion but are constant over animals, and individual animal covariates that are usually assumed constant over time. I also discuss the diý culties of using time-dependent individual animal covariates and some possible solutions. Covariates are usually assumed to be measured without error, and that may not be realistic.},
	language = {en},
	number = {1-4},
	urldate = {2022-11-09},
	journal = {Journal of Applied Statistics},
	author = {Pollock, Kenneth H.},
	month = jan,
	year = {2002},
	pages = {85--102},
	file = {Pollock - 2002 - The use of auxiliary variables in capture-recaptur.pdf:C\:\\Users\\Rob-IUoffice\\Zotero\\storage\\VDRIN33I\\Pollock - 2002 - The use of auxiliary variables in capture-recaptur.pdf:application/pdf},
}

@article{agresti_simple_1994,
	title = {Simple {Capture}-{Recapture} {Models} {Permitting} {Unequal} {Catchability} and {Variable} {Sampling} {Effort}},
	volume = {50},
	issn = {0006341X},
	url = {https://www.jstor.org/stable/2533391?origin=crossref},
	doi = {10.2307/2533391},
	abstract = {We consider two capture-recapture models that imply that the logit of the probability of capture is an additive function of an animal catchability parameter and a parameter reflecting the sampling effort. The models are special cases of the Rasch model, and satisfy the property of quasi-symmetry. One model is log-linear and the other is a latent class model. For the log-linear model, point and interval estimates of the population size are easily obtained using standard software, such as GLIM.},
	language = {en},
	number = {2},
	urldate = {2022-11-09},
	journal = {Biometrics},
	author = {Agresti, Alan},
	month = jun,
	year = {1994},
	pages = {494--500},
	file = {Agresti - 1994 - Simple Capture-Recapture Models Permitting Unequal.pdf:C\:\\Users\\Rob-IUoffice\\Zotero\\storage\\NJ6CSXYF\\Agresti - 1994 - Simple Capture-Recapture Models Permitting Unequal.pdf:application/pdf},
}

@article{huggins_review_2011,
	title = {A {Review} of the {Use} of {Conditional} {Likelihood} in {Capture}-{Recapture} {Experiments}: {A} {Review} of the {Use} of {Conditional} {Likelihood}},
	volume = {79},
	issn = {03067734},
	shorttitle = {A {Review} of the {Use} of {Conditional} {Likelihood} in {Capture}-{Recapture} {Experiments}},
	url = {https://onlinelibrary.wiley.com/doi/10.1111/j.1751-5823.2011.00157.x},
	doi = {10.1111/j.1751-5823.2011.00157.x},
	abstract = {We present a modern perspective of the conditional likelihood approach to the analysis of capturerecapture experiments, which shows the conditional likelihood to be a member of generalized linear model (GLM). Hence, there is the potential to apply the full range of GLM methodologies. To put this method in context, we first review some approaches to capture-recapture experiments with heterogeneous capture probabilities in closed populations, covering parametric and non-parametric mixture models and the use of covariates. We then review in more detail the analysis of capturerecapture experiments when the capture probabilities depend on a covariate.},
	language = {en},
	number = {3},
	urldate = {2022-11-17},
	journal = {International Statistical Review},
	author = {Huggins, Richard and Hwang, Wen-Han},
	month = dec,
	year = {2011},
	pages = {385--400},
	file = {Huggins and Hwang - 2011 - A Review of the Use of Conditional Likelihood in C.pdf:C\:\\Users\\Rob-IUoffice\\Zotero\\storage\\DM7BXX8Q\\Huggins and Hwang - 2011 - A Review of the Use of Conditional Likelihood in C.pdf:application/pdf},
}

@article{stoklosa_heterogeneous_2011,
	title = {Heterogeneous {Capture}-{Recapture} {Models} with {Covariates}: {A} {Partial} {Likelihood} {Approach} for {Closed} {Populations}},
	volume = {67},
	issn = {0006341X},
	shorttitle = {Heterogeneous {Capture}-{Recapture} {Models} with {Covariates}},
	url = {https://onlinelibrary.wiley.com/doi/10.1111/j.1541-0420.2011.01596.x},
	doi = {10.1111/j.1541-0420.2011.01596.x},
	abstract = {In practice, when analyzing data from a capture–recapture experiment it is tempting to apply modern advanced statistical methods to the observed capture histories. However, unless the analysis takes into account that the data have only been collected from individuals who have been captured at least once, the results may be biased. Without the development of new software packages, methods such as generalized additive models, generalized linear mixed models, and simulation–extrapolation cannot be readily implemented. In contrast, the partial likelihood approach allows the analysis of a capture–recapture experiment to be conducted using commonly available software. Here we examine the eﬃciency of this approach and apply it to several data sets.},
	language = {en},
	number = {4},
	urldate = {2022-11-17},
	journal = {Biometrics},
	author = {Stoklosa, Jakub and Hwang, Wen-Han and Wu, Sheng-Hai and Huggins, Richard},
	month = dec,
	year = {2011},
	pages = {1659--1665},
	file = {Stoklosa et al. - 2011 - Heterogeneous Capture-Recapture Models with Covari.pdf:C\:\\Users\\Rob-IUoffice\\Zotero\\storage\\LQ4NXER8\\Stoklosa et al. - 2011 - Heterogeneous Capture-Recapture Models with Covari.pdf:application/pdf},
}

@article{king_capturerecapture_2016,
	title = {Capture–recapture abundance estimation using a semi-complete data likelihood approach},
	volume = {10},
	issn = {1932-6157},
	url = {https://projecteuclid.org/journals/annals-of-applied-statistics/volume-10/issue-1/Capturerecapture-abundance-estimation-using-a-semi-complete-data-likelihood-approach/10.1214/15-AOAS890.full},
	doi = {10.1214/15-AOAS890},
	language = {en},
	number = {1},
	urldate = {2022-11-20},
	journal = {The Annals of Applied Statistics},
	author = {King, Ruth and McClintock, Brett T. and Kidney, Darren and Borchers, David},
	month = mar,
	year = {2016},
	pages = {264--285},
	file = {King et al. - 2016 - Capture–recapture abundance estimation using a sem.pdf:C\:\\Users\\Rob-IUoffice\\Zotero\\storage\\6CB99QZZ\\King et al. - 2016 - Capture–recapture abundance estimation using a sem.pdf:application/pdf},
}

@article{di_cecco_bayesian_2020,
	title = {Bayesian latent class models for capture–recapture in the presence of missing data},
	volume = {62},
	issn = {0323-3847, 1521-4036},
	url = {https://onlinelibrary.wiley.com/doi/10.1002/bimj.201900111},
	doi = {10.1002/bimj.201900111},
	abstract = {We propose a method for estimating the size of a population in a multiple record system in the presence of missing data. The method is based on a latent class model where the parameters and the latent structure are estimated using a Gibbs sampler. The proposed approach is illustrated through the analysis of a data set already known in the literature, which consists of five registrations of neural tube defects.},
	language = {en},
	number = {4},
	urldate = {2022-11-20},
	journal = {Biometrical Journal},
	author = {Di Cecco, Davide and Di Zio, Marco and Liseo, Brunero},
	month = jul,
	year = {2020},
	pages = {957--969},
	file = {Di Cecco et al. - 2020 - Bayesian latent class models for capture–recapture.pdf:C\:\\Users\\Rob-IUoffice\\Zotero\\storage\\XPQKFJHL\\Di Cecco et al. - 2020 - Bayesian latent class models for capture–recapture.pdf:application/pdf},
}

@article{bonner_mcmcmc_2014,
	title = {{MC}({MC}){MC}: exploring {Monte} {Carlo} integration within {MCMC} for mark-recapture models with individual covariates},
	volume = {5},
	issn = {2041210X},
	shorttitle = {{MC}({MC}){MC}},
	url = {https://onlinelibrary.wiley.com/doi/10.1111/2041-210X.12095},
	doi = {10.1111/2041-210X.12095},
	language = {en},
	number = {12},
	urldate = {2022-11-20},
	journal = {Methods in Ecology and Evolution},
	author = {Bonner, Simon and Schofield, Matthew},
	editor = {Cooch, Evan},
	month = dec,
	year = {2014},
	pages = {1305--1315},
	file = {Bonner and Schofield - 2014 - MC(MC)MC exploring Monte Carlo integration within.pdf:C\:\\Users\\Rob-IUoffice\\Zotero\\storage\\DAT2ASAV\\Bonner and Schofield - 2014 - MC(MC)MC exploring Monte Carlo integration within.pdf:application/pdf},
}

@article{royle_analysis_2009,
	title = {Analysis of {Capture}-{Recapture} {Models} with {Individual} {Covariates} {Using} {Data} {Augmentation}},
	volume = {65},
	issn = {0006341X},
	url = {https://onlinelibrary.wiley.com/doi/10.1111/j.1541-0420.2008.01038.x},
	doi = {10.1111/j.1541-0420.2008.01038.x},
	abstract = {I consider the analysis of capture–recapture models with individual covariates that inﬂuence detection probability. Bayesian analysis of the joint likelihood is carried out using a ﬂexible data augmentation scheme that facilitates analysis by Markov chain Monte Carlo methods, and a simple and straightforward implementation in freely available software. This approach is applied to a study of meadow voles (Microtus pennsylvanicus) in which auxiliary data on a continuous covariate (body mass) are recorded, and it is thought that detection probability is related to body mass. In a second example, the model is applied to an aerial waterfowl survey in which a double-observer protocol is used. The fundamental unit of observation is the cluster of individual birds, and the size of the cluster (a discrete covariate) is used as a covariate on detection probability.},
	language = {en},
	number = {1},
	urldate = {2022-11-20},
	journal = {Biometrics},
	author = {Royle, J. Andrew},
	month = mar,
	year = {2009},
	pages = {267--274},
	file = {Royle - 2009 - Analysis of Capture-Recapture Models with Individu.pdf:C\:\\Users\\Rob-IUoffice\\Zotero\\storage\\9F5CT8U9\\Royle - 2009 - Analysis of Capture-Recapture Models with Individu.pdf:application/pdf},
}

@article{king_bayesian_2008,
	title = {On the {Bayesian} {Estimation} of a {Closed} {Population} {Size} in the {Presence} of {Heterogeneity} and {Model} {Uncertainty}},
	volume = {64},
	issn = {0006-341X, 1541-0420},
	url = {https://onlinelibrary.wiley.com/doi/10.1111/j.1541-0420.2007.00938.x},
	doi = {10.1111/j.1541-0420.2007.00938.x},
	abstract = {We consider the estimation of the size of a closed population, often of interest for wild animal populations, using a capture–recapture study. The estimate of the total population size can be very sensitive to the choice of model used to ﬁt to the data. We consider a Bayesian approach, in which we consider all eight plausible models initially described by Otis et al. (1978, Wildlife Monographs 62, 1–135) within a single framework, including models containing an individual heterogeneity component. We show how we are able to obtain a model-averaged estimate of the total population, incorporating both parameter and model uncertainty. To illustrate the methodology we initially perform a simulation study and analyze two datasets where the population size is known, before considering a real example relating to a population of dolphins oﬀ northeast Scotland.},
	language = {en},
	number = {3},
	urldate = {2022-11-20},
	journal = {Biometrics},
	author = {King, R. and Brooks, S. P.},
	month = sep,
	year = {2008},
	pages = {816--824},
	file = {King and Brooks - 2008 - On the Bayesian Estimation of a Closed Population .pdf:C\:\\Users\\Rob-IUoffice\\Zotero\\storage\\AB5DWID3\\King and Brooks - 2008 - On the Bayesian Estimation of a Closed Population .pdf:application/pdf},
}

@article{royle_analysis_2007,
	title = {Analysis of {Multinomial} {Models} {With} {Unknown} {Index} {Using} {Data} {Augmentation}},
	volume = {16},
	issn = {1061-8600, 1537-2715},
	url = {http://www.tandfonline.com/doi/abs/10.1198/106186007X181425},
	doi = {10.1198/106186007X181425},
	language = {en},
	number = {1},
	urldate = {2022-11-20},
	journal = {Journal of Computational and Graphical Statistics},
	author = {Royle, J. Andrew and Dorazio, Robert M and Link, William A},
	month = mar,
	year = {2007},
	pages = {67--85},
	file = {Royle et al. - 2007 - Analysis of Multinomial Models With Unknown Index .pdf:C\:\\Users\\Rob-IUoffice\\Zotero\\storage\\LYFT7PXW\\Royle et al. - 2007 - Analysis of Multinomial Models With Unknown Index .pdf:application/pdf},
}

@article{madigan_bayesian_1997,
	title = {Bayesian methods for estimation of the size of a closed population},
	volume = {84},
	issn = {0006-3444, 1464-3510},
	url = {https://academic.oup.com/biomet/article-lookup/doi/10.1093/biomet/84.1.19},
	doi = {10.1093/biomet/84.1.19},
	abstract = {A Bayesian methodology for estimating the size of a closed population from multiple incomplete administrative lists is proposed. The approach allows for a variety of dependence structures between the lists, can make use of covariates, and explicitly accounts for model uncertainty. Interval estimates from this approach are compared to frequentist and previously published Bayesian approaches. Several examples are considered.},
	language = {en},
	number = {1},
	urldate = {2022-11-20},
	journal = {Biometrika},
	author = {Madigan, D},
	month = mar,
	year = {1997},
	pages = {19--31},
	file = {Madigan - 1997 - Bayesian methods for estimation of the size of a c.pdf:C\:\\Users\\Rob-IUoffice\\Zotero\\storage\\GZPGXXPA\\Madigan - 1997 - Bayesian methods for estimation of the size of a c.pdf:application/pdf},
}

@article{george_capture-recapture_1992,
	title = {Capture-{Recapture} {Estimation} {Via} {Gibbs} {Sampling}},
	volume = {79},
	abstract = {Capture-recapture models are widely used in the estimation of population sizes. Based on data augmentation considerations, we show how Gibbs sampling can be applied to calculate Bayes estimates in this setting. As a result, formulations which were previously avoided because of analytical and numerical intractability can now be easily considered for practical application. We illustrate this potential by using Gibbs sampling to calculate Bayes estimates for a hierarchical capture-recapture model in a real example.},
	language = {en},
	number = {4},
	journal = {Biometrika},
	author = {George, Edward I},
	month = dec,
	year = {1992},
	pages = {677--683},
	file = {George - 2022 - Capture-Recapture Estimation Via Gibbs Sampling.pdf:C\:\\Users\\Rob-IUoffice\\Zotero\\storage\\IL3IVV7P\\George - 2022 - Capture-Recapture Estimation Via Gibbs Sampling.pdf:application/pdf},
}

@article{smith_bayesian_1991,
	title = {Bayesian {Analyses} for a {Multiple} {Capture}-{Recapture} {Model}},
	volume = {78},
	abstract = {In multiple capture-recapture surveys, the probability of capture can vary between sampling occasions. The model accounting for this variation is known as At. Bayes, empirical Bayes, and Bayes empirical Bayes solutions are given to the problems of interval estimation, decision making, and point estimation of the population size N. When the number of sampling occasions is small to moderate and the number of recaptured units observed on each sampling occasion is moderate, estimates obtained from empirical Bayes and Bayes empirical Bayes methods compare closely to Bayesian methods using a reference prior distribution for the capture probabilities. However, when the number of sampling occasions is large and the number of recaptured units observed on each sampling occasion is small, inferences obtained using different reference priors can differ considerably.},
	language = {en},
	number = {2},
	journal = {Biometrika},
	author = {Smith, Philip J},
	month = jun,
	year = {1991},
	pages = {399--407},
	file = {Smith - 2022 - Bayesian Analyses for a Multiple Capture-Recapture.pdf:C\:\\Users\\Rob-IUoffice\\Zotero\\storage\\XZ5TLXIS\\Smith - 2022 - Bayesian Analyses for a Multiple Capture-Recapture.pdf:application/pdf},
}

@article{smith_bayesian_1988,
	title = {Bayesian {Methods} for {Multiple} {Capture}-{Recapture} {Surveys}},
	volume = {44},
	issn = {0006341X},
	url = {https://www.jstor.org/stable/2531745?origin=crossref},
	doi = {10.2307/2531745},
	abstract = {To estimate the total size of a closed population, a multiple capture-recapture sampling design can be used. This sampling design has been used traditionally to estimate the size of wildlife populations and is becoming more widely used to estimate the size of hard-to-count human populations. This paper presents Bayesian methods for obtaining point and interval estimates from data gathered from capture-recapture surveys. A numerical example involving the estimation of the size of a fish population is given to illustrate the methods.},
	language = {en},
	number = {4},
	urldate = {2022-11-20},
	journal = {Biometrics},
	author = {Smith, Philip J.},
	month = dec,
	year = {1988},
	pages = {1177--1189},
	file = {Smith - 1988 - Bayesian Methods for Multiple Capture-Recapture Su.pdf:C\:\\Users\\Rob-IUoffice\\Zotero\\storage\\TITC55KZ\\Smith - 1988 - Bayesian Methods for Multiple Capture-Recapture Su.pdf:application/pdf},
}

@article{castledine_bayesian_1981,
	title = {A {Bayesian} {Analysis} of {Multiple}-{Recapture} {Sampling} for a {Closed} {Population}},
	volume = {68},
	abstract = {This paper considers from a Bayesian viewpoint inferences about the size of a closed animal population from data obtained by a multiple-recapture sampling scheme. The method developed enables prior information about the population size and the catch probabilities to be utilized to produce considerable improvements in certain cases on ordinary maximum likelihood methods. Several ways of expressing such prior information are explored and a practical example of the uses of these ways is given. The main result of the paper is an approximation to the posterior distribution of sample size that exhibits the contributions made by the likelihood and the prior ideas.},
	language = {en},
	author = {Castledine, B J},
	month = apr,
	year = {1981},
	pages = {197--210},
	file = {Castledine - 2022 - A Bayesian Analysis of Multiple-Recapture Sampling.pdf:C\:\\Users\\Rob-IUoffice\\Zotero\\storage\\SMA99LGZ\\Castledine - 2022 - A Bayesian Analysis of Multiple-Recapture Sampling.pdf:application/pdf},
}

@article{freeman_numerical_1973,
	title = {A {Numerical} {Comparison} {Between} {Sequential} {Tagging} and {Sequential} {Recapture}},
	volume = {60},
	abstract = {This paper investigates by means of numerical solutions two experimental techniques, tagging and recapture, for sequential estimation of the size of a population. It is found that the choice between them depends critically on assumptions made about the sampling cost when sampling without replacement. If this is a constant amount per item sampled, then recapture is clearly preferable to tagging, while if it increases as the number of items remaining to be sampled diminishes then the reverse is true.},
	language = {en},
	number = {3},
	journal = {Biometrika},
	author = {Freeman, P R},
	month = dec,
	year = {1973},
	pages = {499--508},
	file = {Freeman - A Numerical Comparison Between Sequential Tagging .pdf:C\:\\Users\\Rob-IUoffice\\Zotero\\storage\\N6R4D7VA\\Freeman - A Numerical Comparison Between Sequential Tagging .pdf:application/pdf},
}

@article{freeman_sequential_1972,
	title = {Sequential {Estimation} of the {Size} of a {Population}},
	volume = {59},
	abstract = {The problem of estimating the size of a finite population using sequential sampling is placed in a Bayesian framework, and an approximate numerical solution is obtained by the technique of truncated dynamic programming. The optimal stopping boundaries are compared with those discussed by Samuel.},
	language = {en},
	number = {1},
	journal = {Biometrika},
	author = {Freeman, P R},
	month = apr,
	year = {1972},
	pages = {9--17},
	file = {Freeman - Sequential Estimation of the Size of a Population.pdf:C\:\\Users\\Rob-IUoffice\\Zotero\\storage\\KM9LC7NU\\Freeman - Sequential Estimation of the Size of a Population.pdf:application/pdf},
}

@article{roberts_informative_1967,
	title = {Informative {Stopping} {Rules} and {Inferences} about {Population} {Size}},
	volume = {62},
	language = {en},
	journal = {Journal of the American Statistical Association},
	author = {Roberts, Harry V},
	month = sep,
	year = {1967},
	pages = {763--775},
	file = {Roberts - 2022 - Informative Stopping Rules and Inferences about Po.pdf:C\:\\Users\\Rob-IUoffice\\Zotero\\storage\\7YNC28WX\\Roberts - 2022 - Informative Stopping Rules and Inferences about Po.pdf:application/pdf},
}

@article{chapman_properties_1951,
	title = {Some properties of the hypergeometric distribution with applications to zoological sample censuses.},
	volume = {1},
	language = {en},
	number = {7},
	journal = {UNIVERSITY OF CALIFORNIA PRESS},
	author = {Chapman, Douglas G},
	year = {1951},
	pages = {131--160},
	file = {Chapman - 1951 - Some properties of the hypergeometric distribution.pdf:C\:\\Users\\Rob-IUoffice\\Zotero\\storage\\6WKEA643\\Chapman - 1951 - Some properties of the hypergeometric distribution.pdf:application/pdf},
}

@article{chapman_estimation_1954,
	title = {The {Estimation} of {Biological} {Populations}},
	volume = {25},
	issn = {0003-4851},
	url = {http://projecteuclid.org/euclid.aoms/1177728844},
	doi = {10.1214/aoms/1177728844},
	abstract = {A number of statistical models, underlying the methods used in the estimation of the sizes and other parameters of animal populations, are set up. The relevant estimation equations are given, with their variances and covariances. For the most part the theory is designed for large populations. In setting up the models, consideration has been given to the desideratum of having them conform as closely as possible to the actual practices of animal sampling. To what extent the models do agree with reality is one of the many open questions which are noted in this paper.},
	language = {en},
	number = {1},
	urldate = {2022-11-21},
	journal = {The Annals of Mathematical Statistics},
	author = {Chapman, Douglas G.},
	month = mar,
	year = {1954},
	pages = {1--15},
	file = {Chapman - 1954 - The Estimation of Biological Populations.pdf:C\:\\Users\\Rob-IUoffice\\Zotero\\storage\\YVDHN8AY\\Chapman - 1954 - The Estimation of Biological Populations.pdf:application/pdf},
}

@article{otis_statistical_1978,
	title = {Statistical {Inference} from {Capture} {Data} on {Closed} {Animal} {Populations}},
	url = {http://www.jstor.org/stable/3830650},
	language = {en},
	number = {62,},
	journal = {Wildlife Monographs},
	author = {Otis, David L. and Burnham, Kenneth P. and White, Gary C. and Anderson, David R.},
	year = {1978},
	pages = {3--135},
	file = {Otis et al. - 1978 - Statistical Inference from Capture Data on Closed .pdf:C\:\\Users\\Rob-IUoffice\\Zotero\\storage\\82V7R5TB\\Otis et al. - 1978 - Statistical Inference from Capture Data on Closed .pdf:application/pdf},
}

@book{jeffreys_theory_1967,
	address = {Oxford},
	edition = {3rd},
	title = {Theory of {Probability}},
	publisher = {Clarendon Press},
	author = {Jeffreys, Harold},
	year = {1967},
}

@incollection{basu_bayesian_1998,
	address = {Singapore},
	title = {Bayesian estimation of the number of undetected errors when both reviewers and errors are heterogeneous},
	booktitle = {Frontiers in {Reliability} {Analysis}},
	publisher = {World Scientific},
	author = {Basu, Sanjib},
	year = {1998},
	pages = {19--36},
}

@article{woodbury_mathematical_1978,
	title = {Mathematical typology: a grade of membership technique for obtaining disease definition},
	volume = {11},
	doi = {10.1016/0010-4809(78)90012-5},
	number = {3},
	journal = {Computers and Biomedical Research},
	author = {Woodbury, Max and Clive, Jonathan and Garson, Arthur},
	year = {1978},
	pages = {277--298},
}

@article{zwane_implementing_2003,
	title = {Implementing the parametric bootstrap in capture–recapture models with continuous covariates},
	volume = {65},
	issn = {01677152},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0167715203002293},
	doi = {10.1016/j.spl.2003.07.010},
	abstract = {The parametric bootstrap is a method for variance estimation advocated by many researchers in multiple capture studies. Most applications thus far used the parametric bootstrap in log-linear modelling, that is, where there are possibly categorical covariates which relate to the probabilities of capture. In this article we present an algorithm for the parametric bootstrap that can be used when there are continuous covariates.},
	language = {en},
	number = {2},
	urldate = {2022-12-02},
	journal = {Statistics \& Probability Letters},
	author = {Zwane, E.N and van der Heijden, P.G.M},
	month = nov,
	year = {2003},
	pages = {121--125},
	file = {Zwane and van der Heijden - 2003 - Implementing the parametric bootstrap in capture–r.pdf:C\:\\Users\\Rob-IUoffice\\Zotero\\storage\\F7ACMSRJ\\Zwane and van der Heijden - 2003 - Implementing the parametric bootstrap in capture–r.pdf:application/pdf},
}

@article{herliansyah_laplace_2022,
	title = {Laplace {Approximations} for {Capture}–{Recapture} {Models} in the {Presence} of {Individual} {Heterogeneity}},
	volume = {27},
	issn = {1085-7117, 1537-2693},
	url = {https://link.springer.com/10.1007/s13253-022-00486-2},
	doi = {10.1007/s13253-022-00486-2},
	abstract = {Abstract
            Capture–recapture studies are common for collecting data on wildlife populations. Populations in such studies are often subject to different forms of heterogeneity that may influence their associated demographic rates. We focus on the most challenging of these relating to individual heterogeneity. We consider (i) continuous time-varying individual covariates and (ii) individual random effects. In general, the associated likelihood is not available in closed form but only expressible as an analytically intractable integral. The integration is specified over (i) the unknown individual covariate values (if an individual is not observed, its associated covariate value is also unknown) and (ii) the unobserved random effect terms. Previous approaches to dealing with these issues include numerical integration and Bayesian data augmentation techniques. However, as the number of individuals observed and/or capture occasions increases, these methods can become computationally expensive. We propose a new and efficient approach that approximates the analytically intractable integral in the likelihood via a Laplace approximation. We find that for the situations considered, the Laplace approximation performs as well as, or better, than alternative approaches, yet is substantially more efficient.Supplementary materials accompanying this paper appear on-line},
	language = {en},
	number = {3},
	urldate = {2022-12-03},
	journal = {Journal of Agricultural, Biological and Environmental Statistics},
	author = {Herliansyah, Riki and King, Ruth and King, Stuart},
	month = sep,
	year = {2022},
	pages = {401--418},
	file = {Herliansyah et al. - 2022 - Laplace Approximations for Capture–Recapture Model.pdf:C\:\\Users\\Rob-IUoffice\\Zotero\\storage\\MMHN2KRA\\Herliansyah et al. - 2022 - Laplace Approximations for Capture–Recapture Model.pdf:application/pdf},
}

@article{sandland_statistical_1984,
	title = {Statistical {Inference} for {Poisson} and {Multinomial} {Models} for {Capture}- {Recapture} {Experiments}},
	volume = {71},
	abstract = {The classical multinomial model used for estimating the size of a closed population is compared to the highly flexible Poisson models introduced by Cormack (1981). The multinomial model, and generalizations of it which allow for dependence between samples, may be obtained from that of Cormack by conditioning on the population size. The maximum likelihood estimators for N, the population size, and 0, the vector of parameters describing the capture process, are the same in both models. Completely general formulae for the asymptotic variances of the maximum likelihood estimates of N for both models are given. The substantial differences between the variances under the two models are discussed. Hypotheses concerning 0 may be tested using the log likelihood ratio; the procedures which result from both models are asymptotically equivalent under the null hypothesis but differ in power under the alternative.},
	language = {en},
	number = {1},
	journal = {Biometrika},
	author = {Sandland, R L and Cormack, R M},
	year = {1984},
	pages = {27--33},
	file = {Sandland and Cormack - 2023 - Statistical Inference for Poisson and Multinomial .pdf:C\:\\Users\\Rob-IUoffice\\Zotero\\storage\\9EQRFEV9\\Sandland and Cormack - 2023 - Statistical Inference for Poisson and Multinomial .pdf:application/pdf},
}

@article{ishwaran_gibbs_2001,
	title = {Gibbs {Sampling} {Methods} for {Stick}-{Breaking} {Priors}},
	volume = {96},
	issn = {0162-1459, 1537-274X},
	url = {http://www.tandfonline.com/doi/abs/10.1198/016214501750332758},
	doi = {10.1198/016214501750332758},
	language = {en},
	number = {453},
	urldate = {2023-03-05},
	journal = {Journal of the American Statistical Association},
	author = {Ishwaran, Hemant and James, Lancelot F},
	month = mar,
	year = {2001},
	pages = {161--173},
	file = {Ishwaran and James - 2001 - Gibbs Sampling Methods for Stick-Breaking Priors.pdf:C\:\\Users\\Rob-IUoffice\\Zotero\\storage\\63JACPKM\\Ishwaran and James - 2001 - Gibbs Sampling Methods for Stick-Breaking Priors.pdf:application/pdf},
}

@article{rubin_inference_1976,
	title = {Inference and {Missing} {Data}},
	volume = {63},
	number = {3},
	journal = {Biometrika},
	author = {Rubin, Donald B},
	month = dec,
	year = {1976},
	pages = {581--592},
	file = {Rubin - Inference and Missing Data.pdf:C\:\\Users\\Rob-IUoffice\\Zotero\\storage\\LBFW9H3T\\Rubin - Inference and Missing Data.pdf:application/pdf},
}

@article{rubin_bayesian_1981,
	title = {The {Bayesian} {Bootstrap}},
	volume = {9},
	number = {1},
	journal = {The Annals of Statistics},
	author = {Rubin, Donald B},
	month = jan,
	year = {1981},
	pages = {130--134},
	file = {1981-Rubin-BayesianBootstrap.pdf:C\:\\Users\\Rob-IUoffice\\Zotero\\storage\\AIXSK8WY\\1981-Rubin-BayesianBootstrap.pdf:application/pdf},
}
