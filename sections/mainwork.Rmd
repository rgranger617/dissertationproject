---
title: ''
output: pdf_document
---

\newpage
\section{Capture-Recapture with Covariates: The Bayesian Logistic Capture-Recapture Model with Extensions}
\label{sec:CRwithCovariates}

In this section, we develop a Bayesian procedure for the multiple-list capture-recapture (CR) problem with covariates. Perhaps the most ubiquitous technique in solving the CR problem with multiple-lists is through the frequentist technique of log-linear models \citep{fienberg_multiple_1972}. Using multiple lists ($J\ge 2$) can be beneficial in that we have more detailed patterns, which can lead to better inference. The downside is that as the number of lists increases, the number of possible patterns grows exponentially. For example, with just two lists, there are only four possible patterns: 1) the individual shows up on both lists, 2) the individual shows up only on list 1, 3) the individual shows up only on list 2, or 4) the individual shows up on neither list.  The number of possible patterns can be calculated as $2^J$, so a dataset with 30 lists would have over a billion possible patterns.  Not only could this become computationally expensive, but it also leads to issues of sparsity, i.e., many of the potential patterns will not appear in the data. In \cite{manriquevallier_bayesian_2016}, they analyze a dataset about killings in Casanare, Colombia which contains 15 lists.  They note that only 70 of the potential $2^{15}=32,768$ capture patterns are present and as a result were unable to successfully compute a solution using log-linear models. 

Even data with much fewer lists can still have issues of sparsity. To get around this issue, we present the Bayesian Logistic Regression Capture-Recapture model that relies on an assumption of conditional independence. First, since the method is Bayesian, we have the added benefit of allowing the practitioner to insert prior belief or knowledge into the estimation procedure. Bayesian methods also are known to assist with sparsity in that they essentially "create" data to fill in the sparse areas. In addition, the assumption of conditional independence, while strong, allows for a reduction in the complexity and sparsity issue. The conditional independence assumption states that given the covariates, the probability of capture on one list is unaffected by another list. 

Unlike most popular existing methods, the method presented here introduces the ability to insert covariates to guide in the estimation of the capture probability. Instead of relying on stratification that essentially only allows for discrete covariates, we implement conditionally independent logistic regressions on each of the lists to determine the probability of capture (or inversely, the probability of non-capture). Typically with regression, the distribution of the covariate is irrelevant so it does not matter whether it is discrete or continuous.  Unfortunately, since we're dealing with what amounts to a missing data problem, but the missing data is not missing at random \citep{rubin_inference_1976}, the distribution of the covariate matters (see subsection \ref{Sec:selectcovariates}). Nevertheless, while we must be careful how we model the distribution of the covariate, any type of covariate, continuous or discrete, can be used.

Finally, a key concern of any capture-recapture framework is that the estimation is highly dependent on how the model is structured. Different situations may present important characteristics of the problem that need to be carefully considered by the practioner. With that in mind, the desire is to create a methodology that is extensible. Through the use of the full likelihood and a data augmentation approach, we are able to add extensions more readily including more robust ways of handling heterogeneity. In particular, we may be concerned with both "observable" heterogeneity, i.e. the heterogeneity that can be detected through the use of covariates, but we may also be concerned with "unobservable" heterogeneity, i.e, the heterogeneity that persists but for which no covariate information exists. One such method, presented in subsection \ref{Sec:condindependence}, allows for the modeling of this unobservable heterogeneity through the use of latent classes. This assumption also happens to break the perhaps unpalatable assumption of conditional independence mentioned before. Similarly, the covariates that are present may be numerous or may affect the estimation procedure in non-linear ways, so we extend the model to include a variable selection procedure (see subsection \ref{Sec:variableselection}). Additional extensions may be warranted given the problem, but the estimation procedure that uses data augmentation allows for extensions to be added relatively easily.

To summarize, we begin with a Bayesian framework for the capture-recapture problem with covariates (see subsection \ref{Sec:CRbackground}). Next, we propose a specific model following this procedure which we call the Bayesian Logistic Regression Capture-Recapture (BLRCR) model and estimate the posterior through a Markov Chain Monte Carlo (MCMC) algorithm (see subsection \ref{Sec:BLRCRmodel}). The three remaining subsections discuss extensions to specifying the distribution of the covariates (subsection \ref{Sec:selectcovariates}), discovering unobserved heterogeneity (subsection \ref{Sec:condindependence}), and variable selection (subsection \ref{Sec:variableselection}). 


```{r CRmodels, child = 'mainworksubsections/CRmodels.Rmd'}
```

```{r selectcovariates, child = 'mainworksubsections/BLRCRmodel.Rmd'}
```

```{r selectcovariates, child = 'mainworksubsections/selectcovariates.Rmd'}
```

```{r hiddencovariates, child = 'mainworksubsections/hiddencovariates.Rmd'}
```

```{r hiddencovariates, child = 'mainworksubsections/variableselection.Rmd'}
```